{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs9E_R5yD48u"
      },
      "source": [
        "# **Assignment \\#2**: Machine Learning MC886/MO444\n",
        "University of Campinas (UNICAMP), Institute of Computing (IC)\n",
        "\n",
        "Prof. Sandra Avila, 2022s2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFS9Oum_RJX9",
        "outputId": "45094cce-bb6b-4ad6-966e-434b6c7b9db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RA1: 213259 Arthur Baia\n",
            "RA2: 200025 José Afonso\n"
          ]
        }
      ],
      "source": [
        "# TODO: RA & Name\n",
        "print(f'RA1: 213259 ' + 'Arthur Baia')\n",
        "print(f'RA2: 200025 ' + 'José Afonso')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVGH2s7fD_03"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Explore **linear regression** and **logistic regression** alternatives and come up with the best possible model for the problems, avoiding overfitting. In particular, predict the performance of students from public schools in the state of São Paulo based on socioeconomic data from SARESP (School Performance Assessment System of the State of São Paulo, or Sistema de Avaliação de Rendimento Escolar do Estado de São Paulo) 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3XDZRGqEwsk"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "These data were aggregated from [Open Data Platform of the Secretary of Education of the State of São Paulo](https://dados.educacao.sp.gov.br/) (*Portal de Dados Abertos da Secretaria da Educação do Estado de São Paulo*). The dataset is based on two data sources: [SARESP questionnaire](https://dados.educacao.sp.gov.br/dataset/question%C3%A1rios-saresp) and [SARESP test](https://dados.educacao.sp.gov.br/dataset/profici%C3%AAncia-do-sistema-de-avalia%C3%A7%C3%A3o-de-rendimento-escolar-do-estado-de-s%C3%A3o-paulo-saresp-por), conducted in 2021 with students from the 5th and 9th year of Primary School and 3rd year of Highschool. The questionnaire comprehends 63 socio-economical questions, and it is available at the [link](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing)), and the test is composed of questions of Portuguese, Mathematics, and Natural Sciences.\n",
        "\n",
        "\n",
        "**Data Dictionary**:\n",
        "\n",
        "- **CD_ALUNO**: Student ID;\n",
        "\n",
        "- **CODESC**: School ID;\n",
        "\n",
        "- **NOMESC**: School Name;\n",
        "\n",
        "- **RegiaoMetropolitana**: Metropolitan region;\n",
        "\n",
        "- **DE**: Name of the Education Board;\n",
        "\n",
        "- **CODMUN**: City ID;\n",
        "\n",
        "- **MUN**: City name;\n",
        "\n",
        "- **SERIE_ANO**: Scholar year;\n",
        "\n",
        "- **TURMA**: Class;\n",
        "\n",
        "- **TP_SEXO**: Sex (Female/Male);\n",
        "\n",
        "- **DT_NASCIMENTO**: Birth date;\n",
        "\n",
        "- **PERIODO**: Period of study (morning, afternoon, evening);\n",
        "\n",
        "- **Tem_Nec**: Whether student has any special needs (1 = yes, 0 = no);\n",
        "\n",
        "- **NEC_ESP_1** - **NEC_ESP_5**: Student disabilities;\n",
        "\n",
        "- **Tipo_PROVA**: Exam type (A = Enlarged, B = Braile, C = Common);\n",
        "\n",
        "- **QN**: Student answer to the question N (N= 1, ... , 63), see  questions in [questionnaire](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing));\n",
        "\n",
        "- **porc_ACERT_lp**: Percentage of correct answers in the Portuguese test;\n",
        "\n",
        "- **porc_ACERT_MAT**: Percentage of correct answers in the Mathematics test;\n",
        "\n",
        "- **porc_ACERT_CIE**: Percentage of correct answers in the Natural Sciences test;\n",
        "\n",
        "- **nivel_profic_lp**: Proficiency level in the Portuguese test;\n",
        "\n",
        "- **nivel_profic_mat**: Proficiency level in the Mathematics test;\n",
        "\n",
        "- **nivel_profic_cie**:  Proficiency level in the Natural Sciences test.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "You must respect the following training/test split:\n",
        "- SARESP_train.csv\n",
        "- SARESP_test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FAA8hsZUseO"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "This part of the assignment aims to predict students' performance on Portuguese, Mathematics, and Natural Sciences tests (target values: `porc_ACERT_lp`, `porc_ACERT_MAT`, and  `porc_ACERT_CIE`) based on their socioeconomic data. Then, at this point, you have to **drop the columns `nivel_profic_lp`, `nivel_profic_mat`** and **`nivel_profic_cie`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d495CmpCltx"
      },
      "source": [
        "### Activities\n",
        "\n",
        "1. (3.5 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org). Keep in mind that friends don't let friends use testing data for training :-)\n",
        "\n",
        "Note: Before we start an ML project, we always conduct a brief exploratory analysis :D \n",
        "\n",
        "Some factors to consider: Are there any outliers? Are there missing values? How will you handle categorical variables? Are there any features with low correlation with the target variables? What happens if you drop them?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y0QxxH1KgE1",
        "outputId": "c80087fa-d4a6-4cfb-dbb8-e0ff167ae8f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8143/3442260541.py:9: DtypeWarning: Columns (78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"SARESP_train.csv\")\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load and preprocess your dataset.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"SARESP_train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "DAADl99uoJp1",
        "outputId": "aecc2d5c-d89c-4b7f-c957-cfe195d94a0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>NOMESC</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>...</th>\n",
              "      <th>NEC_ESP_4</th>\n",
              "      <th>NEC_ESP_5</th>\n",
              "      <th>Tipo_PROVA</th>\n",
              "      <th>Tem_Nec</th>\n",
              "      <th>porc_ACERT_lp</th>\n",
              "      <th>porc_ACERT_MAT</th>\n",
              "      <th>porc_ACERT_CIE</th>\n",
              "      <th>nivel_profic_lp</th>\n",
              "      <th>nivel_profic_mat</th>\n",
              "      <th>nivel_profic_cie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26270013</td>\n",
              "      <td>JULIO FORTES</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>41.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>20.8</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30756614</td>\n",
              "      <td>MESSIAS FREIRE PROFESSOR</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>83.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.7</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Avançado</td>\n",
              "      <td>Adequado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26014872</td>\n",
              "      <td>JOSE CONTI</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>58.3</td>\n",
              "      <td>37.5</td>\n",
              "      <td>54.2</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25739025</td>\n",
              "      <td>NAPOLEAO DE CARVALHO FREIRE PROFESSOR</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>29.2</td>\n",
              "      <td>29.2</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27363009</td>\n",
              "      <td>RESIDENCIAL BORDON</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>79.2</td>\n",
              "      <td>41.7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120591</th>\n",
              "      <td>28799794</td>\n",
              "      <td>ENNIO CHIESA PROFESSOR</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>79.2</td>\n",
              "      <td>66.7</td>\n",
              "      <td>83.3</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Adequado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120592</th>\n",
              "      <td>27825068</td>\n",
              "      <td>HELIO HELENE</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120593</th>\n",
              "      <td>23873470</td>\n",
              "      <td>ALBERTO SANTOS DUMONT</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>41.7</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120594</th>\n",
              "      <td>31376275</td>\n",
              "      <td>FRANCISCO BONFIM</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>45.8</td>\n",
              "      <td>70.8</td>\n",
              "      <td>54.2</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120595</th>\n",
              "      <td>28109335</td>\n",
              "      <td>MAGDALENA SANSEVERINO GROSSO PROFESSORA</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>37.5</td>\n",
              "      <td>16.7</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120596 rows × 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        CD_ALUNO                                   NOMESC Q1 Q2 Q3 Q4 Q5 Q6  \\\n",
              "0       26270013                             JULIO FORTES  B  E  E  E  E  E   \n",
              "1       30756614                 MESSIAS FREIRE PROFESSOR  B  D  E  C  E  E   \n",
              "2       26014872                               JOSE CONTI  B  E  B  D  E  B   \n",
              "3       25739025    NAPOLEAO DE CARVALHO FREIRE PROFESSOR  B  D  E  D  C  E   \n",
              "4       27363009                       RESIDENCIAL BORDON  B  D  E  E  E  E   \n",
              "...          ...                                      ... .. .. .. .. .. ..   \n",
              "120591  28799794                   ENNIO CHIESA PROFESSOR  A  E  E  E  E  E   \n",
              "120592  27825068                             HELIO HELENE  B  D  D  D  D  D   \n",
              "120593  23873470                    ALBERTO SANTOS DUMONT  A  E  E  E  E  E   \n",
              "120594  31376275                         FRANCISCO BONFIM  B  E  C  C  D  B   \n",
              "120595  28109335  MAGDALENA SANSEVERINO GROSSO PROFESSORA  A  A  A  A  A  A   \n",
              "\n",
              "       Q7 Q8  ... NEC_ESP_4 NEC_ESP_5 Tipo_PROVA Tem_Nec porc_ACERT_lp  \\\n",
              "0       E  E  ...       NaN       NaN          C       0          41.7   \n",
              "1       E  E  ...       NaN       NaN          C       0          83.3   \n",
              "2       D  C  ...       NaN       NaN          C       0          58.3   \n",
              "3       D  D  ...       NaN       NaN          C       0          29.2   \n",
              "4       E  C  ...       NaN       NaN          C       0          79.2   \n",
              "...    .. ..  ...       ...       ...        ...     ...           ...   \n",
              "120591  E  E  ...       NaN       NaN          C       0          79.2   \n",
              "120592  D  D  ...       NaN       NaN          C       0          37.5   \n",
              "120593  D  D  ...       NaN       NaN          C       0          50.0   \n",
              "120594  B  A  ...       NaN       NaN          C       1          45.8   \n",
              "120595  A  A  ...       NaN       NaN          C       1          37.5   \n",
              "\n",
              "       porc_ACERT_MAT porc_ACERT_CIE   nivel_profic_lp  nivel_profic_mat  \\\n",
              "0                20.8           20.8  Abaixo do Básico  Abaixo do Básico   \n",
              "1               100.0           66.7          Adequado          Avançado   \n",
              "2                37.5           54.2            Básico            Básico   \n",
              "3                29.2           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "4                41.7           50.0          Adequado  Abaixo do Básico   \n",
              "...               ...            ...               ...               ...   \n",
              "120591           66.7           83.3          Adequado            Básico   \n",
              "120592           25.0           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "120593           37.5           41.7            Básico  Abaixo do Básico   \n",
              "120594           70.8           54.2  Abaixo do Básico            Básico   \n",
              "120595           16.7           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "\n",
              "        nivel_profic_cie  \n",
              "0       Abaixo do Básico  \n",
              "1               Adequado  \n",
              "2                 Básico  \n",
              "3       Abaixo do Básico  \n",
              "4                 Básico  \n",
              "...                  ...  \n",
              "120591          Adequado  \n",
              "120592  Abaixo do Básico  \n",
              "120593  Abaixo do Básico  \n",
              "120594  Abaixo do Básico  \n",
              "120595  Abaixo do Básico  \n",
              "\n",
              "[120596 rows x 88 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePztAuVOoMe1",
        "outputId": "bbde7cd6-825a-4234-ea16-40b77629606e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>CODMUN</th>\n",
              "      <th>CODESC</th>\n",
              "      <th>NEC_ESP_5</th>\n",
              "      <th>Tem_Nec</th>\n",
              "      <th>porc_ACERT_lp</th>\n",
              "      <th>porc_ACERT_MAT</th>\n",
              "      <th>porc_ACERT_CIE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205960e+05</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.734087e+07</td>\n",
              "      <td>364.349075</td>\n",
              "      <td>279415.870510</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.019818</td>\n",
              "      <td>60.151213</td>\n",
              "      <td>52.225829</td>\n",
              "      <td>56.928877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.946464e+06</td>\n",
              "      <td>220.098318</td>\n",
              "      <td>394245.824543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.139376</td>\n",
              "      <td>21.730825</td>\n",
              "      <td>21.262466</td>\n",
              "      <td>18.441383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.739548e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.529711e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>15568.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.700000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>45.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.712102e+07</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>35178.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>58.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.910558e+07</td>\n",
              "      <td>582.000000</td>\n",
              "      <td>901573.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.200000</td>\n",
              "      <td>66.700000</td>\n",
              "      <td>70.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.796186e+07</td>\n",
              "      <td>793.000000</td>\n",
              "      <td>926103.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD_ALUNO         CODMUN         CODESC  NEC_ESP_5        Tem_Nec  \\\n",
              "count  1.205960e+05  120596.000000  120596.000000        0.0  120596.000000   \n",
              "mean   2.734087e+07     364.349075  279415.870510        NaN       0.019818   \n",
              "std    2.946464e+06     220.098318  394245.824543        NaN       0.139376   \n",
              "min    1.739548e+07     100.000000      24.000000        NaN       0.000000   \n",
              "25%    2.529711e+07     100.000000   15568.000000        NaN       0.000000   \n",
              "50%    2.712102e+07     336.000000   35178.000000        NaN       0.000000   \n",
              "75%    2.910558e+07     582.000000  901573.000000        NaN       0.000000   \n",
              "max    3.796186e+07     793.000000  926103.000000        NaN       1.000000   \n",
              "\n",
              "       porc_ACERT_lp  porc_ACERT_MAT  porc_ACERT_CIE  \n",
              "count  120596.000000   120596.000000   120596.000000  \n",
              "mean       60.151213       52.225829       56.928877  \n",
              "std        21.730825       21.262466       18.441383  \n",
              "min         0.000000        0.000000        0.000000  \n",
              "25%        41.700000       37.500000       45.800000  \n",
              "50%        62.500000       50.000000       58.300000  \n",
              "75%        79.200000       66.700000       70.800000  \n",
              "max       100.000000      100.000000      100.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvxhHEeSpaW0",
        "outputId": "7820214f-75cb-4153-bd20-19b11ec475d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'Q63', 'RegiaoMetropolitana', 'DE',\n",
              "       'CODMUN', 'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO',\n",
              "       'DT_NASCIMENTO', 'PERIODO', 'NEC_ESP_1', 'NEC_ESP_2', 'NEC_ESP_3',\n",
              "       'NEC_ESP_4', 'NEC_ESP_5', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check NaNs in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUu_-HXQs_tb",
        "outputId": "9578fccd-4ac9-4664-a6b4-021b02a17856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NEC_ESP_5           120596\n",
              "NEC_ESP_4           120595\n",
              "NEC_ESP_3           120520\n",
              "NEC_ESP_2           120489\n",
              "NEC_ESP_1           118206\n",
              "                     ...  \n",
              "Q26                      0\n",
              "Q25                      0\n",
              "Q24                      0\n",
              "Q23                      0\n",
              "nivel_profic_cie         0\n",
              "Length: 88, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum(axis=0).sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since There are a lot NaN's in the NEC_ESP columns, they will be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'Q63', 'RegiaoMetropolitana', 'DE',\n",
              "       'CODMUN', 'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO',\n",
              "       'DT_NASCIMENTO', 'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def drop_nec_columns(df):\n",
        "    for i in range(1, 6):\n",
        "        df.drop(columns=[f'NEC_ESP_{i}'], inplace=True)\n",
        "drop_nec_columns(df)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the questions {Q0, .., Q63} and their meaning and possible values, it's needed to transform them into numerical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'RegiaoMetropolitana', 'DE', 'CODMUN',\n",
              "       'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO', 'DT_NASCIMENTO',\n",
              "       'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'nivel_profic_lp', 'nivel_profic_mat',\n",
              "       'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def question_map(df):\n",
        "\n",
        "    ordinal_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n",
        "    inversed_ordinal_map = {'A': 5, 'B': 4, 'C': 3, 'D': 2, 'E': 1}\n",
        "    dont_know_ordinal_map = {'A': 1, 'B': 2, 'C': 3, 'D': 1, 'E': 2}\n",
        "    inversed_dont_know_ordinal_map = {'A': 4, 'B': 3, 'C': 2, 'D': 1, 'E': 2} #applied penalty for don't know anwser\n",
        "    home_ordinal_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
        "    miss_someone_map = {'A': 1, 'B': 1, 'C': 1, 'D': 0}\n",
        "    someone_helped_map = {'A': 2, 'B': 1, 'C': 1, 'D': 0}\n",
        "\n",
        "    for q in range(1, 64):\n",
        "        if (q <= 8 or (q > 26 and q <= 33) or (q > 33 and q <= 41) or (q > 56 and q <= 58) or q == 60): #ordinal map\n",
        "            df.replace({f'Q{q}': ordinal_map}, inplace=True)\n",
        "        elif ((q > 8 and q <= 26) or q == 59):\n",
        "            df.replace({f'Q{q}': inversed_ordinal_map}, inplace=True) \n",
        "        elif (q == 42):\n",
        "            df.replace({f'Q{q}': inversed_dont_know_ordinal_map}, inplace=True)\n",
        "        elif (q > 42 and q <= 49):\n",
        "            df.replace({f'Q{q}': dont_know_ordinal_map}, inplace=True)\n",
        "        elif (q > 49 and q <= 56):\n",
        "            df.replace({f'Q{q}': home_ordinal_map}, inplace=True)\n",
        "        elif (q == 61):\n",
        "            df.replace({f'Q{q}': miss_someone_map}, inplace=True)\n",
        "        elif (q == 62):\n",
        "            df.replace({f'Q{q}': someone_helped_map}, inplace=True)\n",
        "        else: # 63 question\n",
        "            df = pd.concat([df, pd.get_dummies(df['Q63'], prefix='Q63')], axis=1)\n",
        "            df.drop(columns=[ 'Q63'], inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = question_map(df)\n",
        "df.columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Considering there are many columns related to geographical columns, { 'RegiaoMetropolitana', 'DE', 'CODMUN', 'MUN', 'CODESC' }, we will select only one column related to this \n",
        "matter, because there are no indicator related to social geographical like HDI to correlate to them and if we one hot encode each of these columns there will be a huge increase in dimensionality, so we will chose the 'Regiao metropolitana' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RegiaoMetropolitana\n",
              "Interior                                                   39211\n",
              "Região Metropolitana da Baixada Santista                    7688\n",
              "Região Metropolitana de Campinas                            3465\n",
              "Região Metropolitana de Ribeirão Preto                      6712\n",
              "Região Metropolitana de Sorocaba                            6736\n",
              "Região Metropolitana de São Paulo                          47437\n",
              "Região Metropolitana do Vale do Paraíba e Litoral Norte     9347\n",
              "Name: RegiaoMetropolitana, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['RegiaoMetropolitana'].groupby(df['RegiaoMetropolitana']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_geo(df):\n",
        "    df = pd.concat([df, pd.get_dummies(df['RegiaoMetropolitana'], prefix='RegiaoMetropolitana')], axis=1)\n",
        "    df.drop(columns=['NOMESC', 'MUN', 'CODESC', 'CODMUN', 'RegiaoMetropolitana',  'DE'], inplace=True)\n",
        "    return df\n",
        "df = select_geo(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D',\n",
              "       'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df._get_numeric_data().columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nivel_profic_cie',\n",
              " 'PERIODO',\n",
              " 'TURMA',\n",
              " 'SERIE_ANO',\n",
              " 'TP_SEXO',\n",
              " 'nivel_profic_lp',\n",
              " 'DT_NASCIMENTO',\n",
              " 'Tipo_PROVA',\n",
              " 'nivel_profic_mat']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_categorical_columns(df):\n",
        "    cols = df.columns\n",
        "\n",
        "    num_cols = df._get_numeric_data().columns\n",
        "\n",
        "    return list(set(cols) - set(num_cols))\n",
        "get_categorical_columns(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since birth date is not a numerical category, we turn it into age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         18\n",
              "1         12\n",
              "2         15\n",
              "3         18\n",
              "4         15\n",
              "          ..\n",
              "120591    16\n",
              "120592    13\n",
              "120593    19\n",
              "120594    12\n",
              "120595    17\n",
              "Name: idade, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Replace the birth day with the age of the student\"\"\"\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "def calculate_age(born):\n",
        "    born = datetime.strptime(born, \"%m/%d/%Y\").date()\n",
        "    today = date.today()\n",
        "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
        "\n",
        "\n",
        "df['idade'] = df['DT_NASCIMENTO'].apply(calculate_age)\n",
        "df = df.drop(columns=['DT_NASCIMENTO'])\n",
        "df['idade']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='idade'>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['idade'].groupby(df['idade']).count().plot(kind='bar')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mapping categorical features into numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sex_mapper(df):\n",
        "    sex_map = {'F': 0, 'M': 1}\n",
        "    df.replace({'TP_SEXO': sex_map}, inplace=True)\n",
        "    return df\n",
        "df = sex_mapper(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since more years of schooling may mean more knowledge, we choose to make SERIE_ANO as ordinal aswell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         3\n",
              "1         1\n",
              "2         2\n",
              "3         3\n",
              "4         2\n",
              "         ..\n",
              "120591    2\n",
              "120592    1\n",
              "120593    3\n",
              "120594    1\n",
              "120595    2\n",
              "Name: SERIE_ANO, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def school_year_mapper(df): \n",
        "    school_year_map = {'EM-3ª série': 3, '9º Ano EF': 2, '5º Ano EF': 1}\n",
        "    df.replace({'SERIE_ANO': school_year_map}, inplace=True)\n",
        "    return df\n",
        "df = school_year_mapper(df)\n",
        "df['SERIE_ANO']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Drop column TURMA, since in large scale it is not relevant\"\"\"\n",
        "def drop_turma(df):\n",
        "    df = df.drop(columns=['TURMA'])\n",
        "    return df\n",
        "df = drop_turma(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"One hot encoding on the columns PERIODO, Tipo_PROVA\"\"\"\n",
        "def one_hot_encoding_(df):\n",
        "    df = pd.concat([df, pd.get_dummies(df['PERIODO'], prefix='PERIODO')], axis=1)\n",
        "    df = df.drop(columns=['PERIODO'])\n",
        "    df = pd.concat([df, pd.get_dummies(df['Tipo_PROVA'], prefix='Tipo_PROVA')], axis=1)\n",
        "    df = df.drop(columns=['Tipo_PROVA'])\n",
        "    return df\n",
        "df = one_hot_encoding_(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nivel_profic_cie', 'nivel_profic_lp', 'nivel_profic_mat']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_categorical_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Abaixo do Básico' 'Avançado' 'Básico' 'Adequado']\n",
            "['Abaixo do Básico' 'Adequado' 'Básico' 'Avançado']\n",
            "['Abaixo do Básico' 'Adequado' 'Básico' 'Avançado']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Get unique values of nivel_profic_mat\"\"\"\n",
        "print(df['nivel_profic_mat'].unique())\n",
        "print(df['nivel_profic_lp'].unique())\n",
        "print(df['nivel_profic_cie'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         0\n",
              "1         3\n",
              "2         1\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "120591    1\n",
              "120592    0\n",
              "120593    0\n",
              "120594    1\n",
              "120595    0\n",
              "Name: nivel_profic_mat, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def map_categorical_columns_for_log_reg(df):\n",
        "    \"\"\"Map the categorical columns to numerical values\"\"\"\n",
        "    map_for_log_reg = { 'Abaixo do Básico': 0, 'Adequado': 2, 'Básico': 1, 'Avançado': 3}\n",
        "    df.replace({'nivel_profic_mat': map_for_log_reg}, inplace=True)\n",
        "    df.replace({'nivel_profic_lp': map_for_log_reg}, inplace=True)\n",
        "    df.replace({'nivel_profic_cie': map_for_log_reg}, inplace=True)\n",
        "    return df\n",
        "map_categorical_columns_for_log_reg(df)\n",
        "df['nivel_profic_mat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_categorical_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the columns were rightly transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With all the columns being numbers, we can start to perform numerical analysis such as correlation, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>...</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Sorocaba</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de São Paulo</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte</th>\n",
              "      <th>idade</th>\n",
              "      <th>PERIODO_MANHÃ</th>\n",
              "      <th>PERIODO_NOITE</th>\n",
              "      <th>PERIODO_TARDE</th>\n",
              "      <th>Tipo_PROVA_A</th>\n",
              "      <th>Tipo_PROVA_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205960e+05</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.734087e+07</td>\n",
              "      <td>1.803567</td>\n",
              "      <td>4.183397</td>\n",
              "      <td>4.234850</td>\n",
              "      <td>3.901249</td>\n",
              "      <td>3.994676</td>\n",
              "      <td>3.839248</td>\n",
              "      <td>4.015813</td>\n",
              "      <td>3.542456</td>\n",
              "      <td>4.551519</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055657</td>\n",
              "      <td>0.055856</td>\n",
              "      <td>0.393355</td>\n",
              "      <td>0.077507</td>\n",
              "      <td>15.735464</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.110169</td>\n",
              "      <td>0.207478</td>\n",
              "      <td>0.000912</td>\n",
              "      <td>0.999088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.946464e+06</td>\n",
              "      <td>0.634012</td>\n",
              "      <td>0.942674</td>\n",
              "      <td>1.032048</td>\n",
              "      <td>1.171602</td>\n",
              "      <td>1.033197</td>\n",
              "      <td>1.233479</td>\n",
              "      <td>1.100245</td>\n",
              "      <td>1.272283</td>\n",
              "      <td>0.723518</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229259</td>\n",
              "      <td>0.229644</td>\n",
              "      <td>0.488496</td>\n",
              "      <td>0.267395</td>\n",
              "      <td>2.466339</td>\n",
              "      <td>0.465563</td>\n",
              "      <td>0.313102</td>\n",
              "      <td>0.405502</td>\n",
              "      <td>0.030188</td>\n",
              "      <td>0.030188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.739548e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.529711e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.712102e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.910558e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.796186e+07</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD_ALUNO             Q1             Q2             Q3  \\\n",
              "count  1.205960e+05  120596.000000  120596.000000  120596.000000   \n",
              "mean   2.734087e+07       1.803567       4.183397       4.234850   \n",
              "std    2.946464e+06       0.634012       0.942674       1.032048   \n",
              "min    1.739548e+07       1.000000       1.000000       1.000000   \n",
              "25%    2.529711e+07       1.000000       4.000000       4.000000   \n",
              "50%    2.712102e+07       2.000000       4.000000       5.000000   \n",
              "75%    2.910558e+07       2.000000       5.000000       5.000000   \n",
              "max    3.796186e+07       4.000000       5.000000       5.000000   \n",
              "\n",
              "                  Q4             Q5             Q6             Q7  \\\n",
              "count  120596.000000  120596.000000  120596.000000  120596.000000   \n",
              "mean        3.901249       3.994676       3.839248       4.015813   \n",
              "std         1.171602       1.033197       1.233479       1.100245   \n",
              "min         1.000000       1.000000       1.000000       1.000000   \n",
              "25%         3.000000       3.000000       3.000000       3.000000   \n",
              "50%         4.000000       4.000000       4.000000       4.000000   \n",
              "75%         5.000000       5.000000       5.000000       5.000000   \n",
              "max         5.000000       5.000000       5.000000       5.000000   \n",
              "\n",
              "                  Q8             Q9  ...  \\\n",
              "count  120596.000000  120596.000000  ...   \n",
              "mean        3.542456       4.551519  ...   \n",
              "std         1.272283       0.723518  ...   \n",
              "min         1.000000       3.000000  ...   \n",
              "25%         3.000000       4.000000  ...   \n",
              "50%         4.000000       5.000000  ...   \n",
              "75%         5.000000       5.000000  ...   \n",
              "max         5.000000       5.000000  ...   \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto  \\\n",
              "count                                      120596.000000            \n",
              "mean                                            0.055657            \n",
              "std                                             0.229259            \n",
              "min                                             0.000000            \n",
              "25%                                             0.000000            \n",
              "50%                                             0.000000            \n",
              "75%                                             0.000000            \n",
              "max                                             1.000000            \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Sorocaba  \\\n",
              "count                                      120596.000000      \n",
              "mean                                            0.055856      \n",
              "std                                             0.229644      \n",
              "min                                             0.000000      \n",
              "25%                                             0.000000      \n",
              "50%                                             0.000000      \n",
              "75%                                             0.000000      \n",
              "max                                             1.000000      \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de São Paulo  \\\n",
              "count                                      120596.000000       \n",
              "mean                                            0.393355       \n",
              "std                                             0.488496       \n",
              "min                                             0.000000       \n",
              "25%                                             0.000000       \n",
              "50%                                             0.000000       \n",
              "75%                                             1.000000       \n",
              "max                                             1.000000       \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte  \\\n",
              "count                                      120596.000000                             \n",
              "mean                                            0.077507                             \n",
              "std                                             0.267395                             \n",
              "min                                             0.000000                             \n",
              "25%                                             0.000000                             \n",
              "50%                                             0.000000                             \n",
              "75%                                             0.000000                             \n",
              "max                                             1.000000                             \n",
              "\n",
              "               idade  PERIODO_MANHÃ  PERIODO_NOITE  PERIODO_TARDE  \\\n",
              "count  120596.000000  120596.000000  120596.000000  120596.000000   \n",
              "mean       15.735464       0.682353       0.110169       0.207478   \n",
              "std         2.466339       0.465563       0.313102       0.405502   \n",
              "min        10.000000       0.000000       0.000000       0.000000   \n",
              "25%        15.000000       0.000000       0.000000       0.000000   \n",
              "50%        16.000000       1.000000       0.000000       0.000000   \n",
              "75%        18.000000       1.000000       0.000000       0.000000   \n",
              "max        56.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "        Tipo_PROVA_A   Tipo_PROVA_C  \n",
              "count  120596.000000  120596.000000  \n",
              "mean        0.000912       0.999088  \n",
              "std         0.030188       0.030188  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       1.000000  \n",
              "50%         0.000000       1.000000  \n",
              "75%         0.000000       1.000000  \n",
              "max         1.000000       1.000000  \n",
              "\n",
              "[8 rows x 89 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120596, 89)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outliers detection\n",
        "Since the noly original numerical columns were the porc_ACERT, we will only perform outlier detection on these. The method to find the outliers will be though z-score and standard deviation, it's known that 99% of data is located between -3 std to 3 std, with that in mind we will drop all the data the is beyond this range  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00024876446979999335\n",
            "0.0\n",
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#removing outliers\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_CIE'])) > 3)])/len(df.index)) #less than 0.025%\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_MAT'])) > 3)])/len(df.index))\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_lp'])) > 3)])/len(df.index))\n",
        "\n",
        "df.boxplot(column=['porc_ACERT_lp',\n",
        "       'porc_ACERT_MAT', 'porc_ACERT_CIE'])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there are only 0.02% of data that are outliers, there will be no great effect in dropping it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[(np.abs(stats.zscore(df['porc_ACERT_CIE'])) < 3)]\n",
        "type(df)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing df's for each specific target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cie = df \n",
        "df_mat = df\n",
        "df_lp = df\n",
        "\n",
        "\n",
        "# df_cie = df.drop(columns=['porc_ACERT_lp', 'porc_ACERT_MAT'])\n",
        "\n",
        "# df_mat = df.drop(columns=['porc_ACERT_lp', 'porc_ACERT_CIE'])\n",
        "\n",
        "# df_lp = df.drop(columns=['porc_ACERT_CIE', 'porc_ACERT_MAT'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C',\n",
              "       'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "def tranform_into_lin_reg(df):\n",
        "    \"\"\"Drop all the categorical columns in the dataframe lin_reg_df\"\"\"\n",
        "    df = df.drop(columns=['nivel_profic_mat', 'nivel_profic_lp', 'nivel_profic_cie'])\n",
        "    return df\n",
        "df_cie_lr = tranform_into_lin_reg(df_cie)\n",
        "print(get_categorical_columns(df_cie_lr))\n",
        "df_mat_lr = tranform_into_lin_reg(df_mat)\n",
        "print(get_categorical_columns(df_mat_lr))\n",
        "df_lp_lr  = tranform_into_lin_reg(df_lp)\n",
        "print(get_categorical_columns(df_lp_lr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D',\n",
              "       'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie_lr.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop CD_ALUNO\n",
        "df_cie_lr = df_cie_lr.drop(columns=['CD_ALUNO'])\n",
        "df_mat_lr = df_mat_lr.drop(columns=['CD_ALUNO'])\n",
        "df_lp_lr = df_lp_lr.drop(columns=['CD_ALUNO'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
              "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
              "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31',\n",
              "       'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41',\n",
              "       'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50', 'Q51',\n",
              "       'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60', 'Q61',\n",
              "       'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D',\n",
              "       'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie_lr.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Function to normalize the data\"\"\"\n",
        "def normalize_data(df):\n",
        "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df)\n",
        "    return scaler.transform(df)\n",
        "df_cie_lr = pd.DataFrame(normalize_data(df_cie_lr), columns=df_cie_lr.columns,index=df_cie_lr.index)\n",
        "df_mat_lr = pd.DataFrame(normalize_data(df_mat_lr), columns=df_mat_lr.columns,index=df_mat_lr.index)\n",
        "df_lp_lr = pd.DataFrame(normalize_data(df_lp_lr), columns=df_lp_lr.columns,index=df_lp_lr.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>...</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Sorocaba</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de São Paulo</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte</th>\n",
              "      <th>idade</th>\n",
              "      <th>PERIODO_MANHÃ</th>\n",
              "      <th>PERIODO_NOITE</th>\n",
              "      <th>PERIODO_TARDE</th>\n",
              "      <th>Tipo_PROVA_A</th>\n",
              "      <th>Tipo_PROVA_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.049024e-16</td>\n",
              "      <td>-4.315142e-16</td>\n",
              "      <td>-1.772732e-16</td>\n",
              "      <td>1.222584e-16</td>\n",
              "      <td>-7.637836e-17</td>\n",
              "      <td>-1.132710e-16</td>\n",
              "      <td>7.331380e-17</td>\n",
              "      <td>5.504428e-17</td>\n",
              "      <td>2.946696e-18</td>\n",
              "      <td>4.537912e-16</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.793608e-17</td>\n",
              "      <td>4.019294e-17</td>\n",
              "      <td>1.379054e-17</td>\n",
              "      <td>2.805255e-17</td>\n",
              "      <td>-1.446238e-16</td>\n",
              "      <td>-1.155105e-17</td>\n",
              "      <td>3.500675e-17</td>\n",
              "      <td>-1.183393e-16</td>\n",
              "      <td>-1.284760e-17</td>\n",
              "      <td>1.941283e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.267496e+00</td>\n",
              "      <td>-3.377497e+00</td>\n",
              "      <td>-3.135009e+00</td>\n",
              "      <td>-2.476635e+00</td>\n",
              "      <td>-2.898725e+00</td>\n",
              "      <td>-2.301823e+00</td>\n",
              "      <td>-2.741345e+00</td>\n",
              "      <td>-1.998341e+00</td>\n",
              "      <td>-2.144420e+00</td>\n",
              "      <td>-4.759523e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>-2.325815e+00</td>\n",
              "      <td>-1.465640e+00</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>-3.309161e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.267496e+00</td>\n",
              "      <td>-1.946253e-01</td>\n",
              "      <td>-2.276916e-01</td>\n",
              "      <td>-7.694097e-01</td>\n",
              "      <td>-9.628269e-01</td>\n",
              "      <td>-6.803548e-01</td>\n",
              "      <td>-9.233868e-01</td>\n",
              "      <td>-4.262935e-01</td>\n",
              "      <td>-7.622820e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>-2.982680e-01</td>\n",
              "      <td>-1.465640e+00</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.099038e-01</td>\n",
              "      <td>-1.946253e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>8.420298e-02</td>\n",
              "      <td>5.122103e-03</td>\n",
              "      <td>1.303794e-01</td>\n",
              "      <td>-1.440754e-02</td>\n",
              "      <td>3.597300e-01</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>1.072414e-01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.099038e-01</td>\n",
              "      <td>8.663319e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>9.378157e-01</td>\n",
              "      <td>9.730711e-01</td>\n",
              "      <td>9.411137e-01</td>\n",
              "      <td>8.945717e-01</td>\n",
              "      <td>1.145754e+00</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>1.241872e+00</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>9.182604e-01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.464702e+00</td>\n",
              "      <td>8.663319e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>9.378157e-01</td>\n",
              "      <td>9.730711e-01</td>\n",
              "      <td>9.411137e-01</td>\n",
              "      <td>8.945717e-01</td>\n",
              "      <td>1.145754e+00</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>4.119886e+00</td>\n",
              "      <td>4.111456e+00</td>\n",
              "      <td>1.241872e+00</td>\n",
              "      <td>3.449478e+00</td>\n",
              "      <td>1.632762e+01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>2.841956e+00</td>\n",
              "      <td>1.954418e+00</td>\n",
              "      <td>3.309161e+01</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q1            Q2            Q3            Q4            Q5  \\\n",
              "count  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05   \n",
              "mean   1.049024e-16 -4.315142e-16 -1.772732e-16  1.222584e-16 -7.637836e-17   \n",
              "std    1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00   \n",
              "min   -1.267496e+00 -3.377497e+00 -3.135009e+00 -2.476635e+00 -2.898725e+00   \n",
              "25%   -1.267496e+00 -1.946253e-01 -2.276916e-01 -7.694097e-01 -9.628269e-01   \n",
              "50%    3.099038e-01 -1.946253e-01  7.414143e-01  8.420298e-02  5.122103e-03   \n",
              "75%    3.099038e-01  8.663319e-01  7.414143e-01  9.378157e-01  9.730711e-01   \n",
              "max    3.464702e+00  8.663319e-01  7.414143e-01  9.378157e-01  9.730711e-01   \n",
              "\n",
              "                 Q6            Q7            Q8            Q9           Q10  \\\n",
              "count  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05   \n",
              "mean  -1.132710e-16  7.331380e-17  5.504428e-17  2.946696e-18  4.537912e-16   \n",
              "std    1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00   \n",
              "min   -2.301823e+00 -2.741345e+00 -1.998341e+00 -2.144420e+00 -4.759523e+00   \n",
              "25%   -6.803548e-01 -9.233868e-01 -4.262935e-01 -7.622820e-01  3.296665e-01   \n",
              "50%    1.303794e-01 -1.440754e-02  3.597300e-01  6.198564e-01  3.296665e-01   \n",
              "75%    9.411137e-01  8.945717e-01  1.145754e+00  6.198564e-01  3.296665e-01   \n",
              "max    9.411137e-01  8.945717e-01  1.145754e+00  6.198564e-01  3.296665e-01   \n",
              "\n",
              "       ...  RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto  \\\n",
              "count  ...                                       1.205660e+05            \n",
              "mean   ...                                      -6.793608e-17            \n",
              "std    ...                                       1.000004e+00            \n",
              "min    ...                                      -2.427251e-01            \n",
              "25%    ...                                      -2.427251e-01            \n",
              "50%    ...                                      -2.427251e-01            \n",
              "75%    ...                                      -2.427251e-01            \n",
              "max    ...                                       4.119886e+00            \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Sorocaba  \\\n",
              "count                                       1.205660e+05      \n",
              "mean                                        4.019294e-17      \n",
              "std                                         1.000004e+00      \n",
              "min                                        -2.432228e-01      \n",
              "25%                                        -2.432228e-01      \n",
              "50%                                        -2.432228e-01      \n",
              "75%                                        -2.432228e-01      \n",
              "max                                         4.111456e+00      \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de São Paulo  \\\n",
              "count                                       1.205660e+05       \n",
              "mean                                        1.379054e-17       \n",
              "std                                         1.000004e+00       \n",
              "min                                        -8.052361e-01       \n",
              "25%                                        -8.052361e-01       \n",
              "50%                                        -8.052361e-01       \n",
              "75%                                         1.241872e+00       \n",
              "max                                         1.241872e+00       \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte  \\\n",
              "count                                       1.205660e+05                             \n",
              "mean                                        2.805255e-17                             \n",
              "std                                         1.000004e+00                             \n",
              "min                                        -2.898989e-01                             \n",
              "25%                                        -2.898989e-01                             \n",
              "50%                                        -2.898989e-01                             \n",
              "75%                                        -2.898989e-01                             \n",
              "max                                         3.449478e+00                             \n",
              "\n",
              "              idade  PERIODO_MANHÃ  PERIODO_NOITE  PERIODO_TARDE  \\\n",
              "count  1.205660e+05   1.205660e+05   1.205660e+05   1.205660e+05   \n",
              "mean  -1.446238e-16  -1.155105e-17   3.500675e-17  -1.183393e-16   \n",
              "std    1.000004e+00   1.000004e+00   1.000004e+00   1.000004e+00   \n",
              "min   -2.325815e+00  -1.465640e+00  -3.518703e-01  -5.116614e-01   \n",
              "25%   -2.982680e-01  -1.465640e+00  -3.518703e-01  -5.116614e-01   \n",
              "50%    1.072414e-01   6.822956e-01  -3.518703e-01  -5.116614e-01   \n",
              "75%    9.182604e-01   6.822956e-01  -3.518703e-01  -5.116614e-01   \n",
              "max    1.632762e+01   6.822956e-01   2.841956e+00   1.954418e+00   \n",
              "\n",
              "       Tipo_PROVA_A  Tipo_PROVA_C  \n",
              "count  1.205660e+05  1.205660e+05  \n",
              "mean  -1.284760e-17  1.941283e-16  \n",
              "std    1.000004e+00  1.000004e+00  \n",
              "min   -3.021914e-02 -3.309161e+01  \n",
              "25%   -3.021914e-02  3.021914e-02  \n",
              "50%   -3.021914e-02  3.021914e-02  \n",
              "75%   -3.021914e-02  3.021914e-02  \n",
              "max    3.309161e+01  3.021914e-02  \n",
              "\n",
              "[8 rows x 85 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie_lr.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Function to split the data into train and validation sets\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(df, target, validation_size):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    return train_test_split(X, y, test_size=validation_size, random_state=42)\n",
        "X_train_cie, X_val_cie, y_train_cie, y_val_cie = split_data(df_cie_lr, 'porc_ACERT_CIE', 0.2)\n",
        "X_train_mat, X_val_mat, y_train_mat, y_val_mat = split_data(df_mat_lr, 'porc_ACERT_MAT', 0.2)\n",
        "X_train_lp, X_val_lp, y_train_lp, y_val_lp = split_data(df_lp_lr, 'porc_ACERT_lp', 0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 9.54 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\"\"\"Function to evaluate the model using the validation set and the R2 score\"\"\"\n",
        "def evaluate_model(X_val, y_val, w, b):\n",
        "    from sklearn.metrics import r2_score\n",
        "    y_pred = np.dot(X_val, w) + b\n",
        "    error = y_pred - y_val\n",
        "    mse = (1/X_val.shape[0]) * np.sum(error**2)\n",
        "    return mse, r2_score(y_val, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "D9cpdif9JxFR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Science\n",
            "Epoch: 0, Train Loss: 0.999455676944012, Val Loss: 0.9783903779668446, R2: 0.02351924015435336\n",
            "Epoch: 100, Train Loss: 0.5067604919937725, Val Loss: 0.5033996509661216, R2: 0.49758288230213\n",
            "Epoch: 200, Train Loss: 0.48521611003974097, Val Loss: 0.4821880794091851, R2: 0.5187530532051593\n",
            "Epoch: 300, Train Loss: 0.48141656732154775, Val Loss: 0.4785481303564663, R2: 0.5223858978210114\n",
            "Epoch: 400, Train Loss: 0.48032430818081884, Val Loss: 0.47753852422553683, R2: 0.5233935334070476\n",
            "Epoch: 500, Train Loss: 0.4798407138850806, Val Loss: 0.4770991416335973, R2: 0.5238320584139387\n",
            "Epoch: 600, Train Loss: 0.4795285049588522, Val Loss: 0.47681246044556885, R2: 0.5241181800588605\n",
            "Epoch: 700, Train Loss: 0.4792787107905286, Val Loss: 0.4765782169996437, R2: 0.5243519663094378\n",
            "Epoch: 800, Train Loss: 0.47905992884227183, Val Loss: 0.4763688143708494, R2: 0.5245609602270842\n",
            "Epoch: 900, Train Loss: 0.47886150741050243, Val Loss: 0.4761754349830856, R2: 0.5247539621777926\n",
            "Math\n",
            "Epoch: 0, Train Loss: 0.998244699217712, Val Loss: 0.9749323561147555, R2: 0.02963964761885829\n",
            "Epoch: 100, Train Loss: 0.4597279635062399, Val Loss: 0.4560419549065069, R2: 0.5460966811818738\n",
            "Epoch: 200, Train Loss: 0.4438071240191007, Val Loss: 0.44047537577168394, R2: 0.561590259910589\n",
            "Epoch: 300, Train Loss: 0.4415943955443629, Val Loss: 0.4385144609405497, R2: 0.563541978914061\n",
            "Epoch: 400, Train Loss: 0.44108978204268756, Val Loss: 0.4381595783358078, R2: 0.5638951972755517\n",
            "Epoch: 500, Train Loss: 0.4409320597327389, Val Loss: 0.4380925382843028, R2: 0.563961922938716\n",
            "Epoch: 600, Train Loss: 0.4408690076374719, Val Loss: 0.43808551305848, R2: 0.5639689152193212\n",
            "Epoch: 700, Train Loss: 0.44083857281211053, Val Loss: 0.43808968793098463, R2: 0.5639647599251314\n",
            "Epoch: 800, Train Loss: 0.44082158231647, Val Loss: 0.43809370953267596, R2: 0.5639607571829823\n",
            "Epoch: 900, Train Loss: 0.4408108854968904, Val Loss: 0.4380952942074836, R2: 0.5639591799396022\n",
            "Portuguese\n",
            "Epoch: 0, Train Loss: 1.0009377139785014, Val Loss: 0.9678843414215199, R2: 0.027948083275822988\n",
            "Epoch: 100, Train Loss: 0.46640179095929274, Val Loss: 0.46265217322972496, R2: 0.5353557108858079\n",
            "Epoch: 200, Train Loss: 0.44494068397879, Val Loss: 0.44329112167952994, R2: 0.5548001284300799\n",
            "Epoch: 300, Train Loss: 0.4411454515230004, Val Loss: 0.440225236449785, R2: 0.5578792149350364\n",
            "Epoch: 400, Train Loss: 0.44020564165372955, Val Loss: 0.43960969068552525, R2: 0.5584974111537101\n",
            "Epoch: 500, Train Loss: 0.4399244869546114, Val Loss: 0.43948702825290253, R2: 0.5586206017537004\n",
            "Epoch: 600, Train Loss: 0.4398181364596647, Val Loss: 0.4394624378134194, R2: 0.5586452980761945\n",
            "Epoch: 700, Train Loss: 0.43976409583403614, Val Loss: 0.43945214858000303, R2: 0.5586556316136182\n",
            "Epoch: 800, Train Loss: 0.439728098479958, Val Loss: 0.4394402780941728, R2: 0.5586675532121088\n",
            "Epoch: 900, Train Loss: 0.4396995762744955, Val Loss: 0.4394254610305407, R2: 0.5586824340759553\n",
            "CPU times: user 3min 50s, sys: 2min 46s, total: 6min 37s\n",
            "Wall time: 36.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TODO: Linear Regression. Implement your solution. You cannot use scikit-learn, Keras/TensorFlow, or PyTorch libraries.\n",
        "\n",
        "\n",
        "def linear_regression(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    train_loss, val_loss,  r2_list = [], [], []\n",
        "    w = np.random.rand(X_train.shape[1])*0.001 - 0.0005\n",
        "    b = 0\n",
        "    m = X_train.shape[0]\n",
        "    for i in range(epochs):\n",
        "        y_pred = np.dot(X_train, w) + b\n",
        "        error = y_pred - y_train\n",
        "        mse = (1/m) * np.sum(error**2)\n",
        "        w = w - (learning_rate * (1/m) * np.dot(X_train.T, error))\n",
        "        b = b - (learning_rate * (1/m) * np.sum(error))\n",
        "        mse_val, r2 = evaluate_model(X_val, y_val, w, b)\n",
        "        train_loss.append(mse)\n",
        "        val_loss.append(mse_val)\n",
        "        r2_list.append(r2)\n",
        "        if i % 100 == 0:\n",
        "            print(\"Epoch: {}, Train Loss: {}, Val Loss: {}, R2: {}\".format(\n",
        "                i, mse, mse_val, r2))\n",
        "    return w, b, train_loss, val_loss, r2_list\n",
        "\n",
        "\n",
        "print('Science')\n",
        "w_cie, b_cie, train_loss_cie, val_loss_cie, r2_cie = linear_regression(\n",
        "    X_train_cie, y_train_cie, X_val_cie, y_val_cie, 0.01, 1000)\n",
        "print('Math')\n",
        "w_mat, b_mat,  train_loss_mat, val_loss_mat, r2_mat = linear_regression(\n",
        "    X_train_mat, y_train_mat, X_val_mat, y_val_mat, 0.01, 1000)\n",
        "print('Portuguese')\n",
        "w_lp, b_lp,  train_loss_lp, val_loss_lp, r2_lp = linear_regression(\n",
        "    X_train_lp, y_train_lp, X_val_lp, y_val_lp, 0.01, 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "e4nZrMr_C2X7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5278231743443579\n",
            "0.5641338909335655\n",
            "0.5590048019083095\n",
            "CPU times: user 11 s, sys: 9 s, total: 20 s\n",
            "Wall time: 1.91 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TODO: Linear Regression. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def linear_regression_sklearn(X_train, y_train):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "model_cie = linear_regression_sklearn(X_train_cie, y_train_cie )\n",
        "model_mat = linear_regression_sklearn(X_train_mat, y_train_mat)\n",
        "model_lp = linear_regression_sklearn(X_train_lp, y_train_lp)\n",
        "print(model_cie.score(X_val_cie, y_val_cie))\n",
        "print(model_mat.score(X_val_mat, y_val_mat))\n",
        "print(model_lp.score(X_val_lp, y_val_lp))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBNZQNImKQeo"
      },
      "source": [
        "\n",
        "> What are the conclusions? (1-2 paragraphs)\n",
        "The most obvious conclusion is about time, when the scikit learn library was used to train and validate the models, the total time was 1 s, and when we used our function it took 30 seconds to train. It happened because the library is better optimized than our code, using multi thread programming and many other things.\n",
        "In terms of results, both produced the same R^2 score for all the models, showing that our solution may be as good as the one from library but much slower\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADxPBRhuK_Vq"
      },
      "source": [
        "2. (1 point) Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions with Normal Equation. What are the conclusions?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RSZ1pLItNVbU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate:  0.01\n",
            "0.5187501784822446\n",
            "0.5579244827782425\n",
            "0.5527596718112967\n",
            "Learning rate:  0.001\n",
            "0.5233539800193253\n",
            "0.5587029676946329\n",
            "0.5539154667853021\n",
            "Learning rate:  0.0001\n",
            "0.5225551205617351\n",
            "0.5593011854217729\n",
            "0.5535474364406399\n"
          ]
        }
      ],
      "source": [
        "# TODO: Gradient Descent (GD) with 3 different learning rates. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "def linear_regression_sklearn(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    model = SGDRegressor(alpha=learning_rate, max_iter=epochs)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "lrs = [0.01, 0.001, 0.0001]\n",
        "for lr in lrs:\n",
        "    print(\"Learning rate: \", lr)\n",
        "    model_cie = linear_regression_sklearn(X_train_cie, y_train_cie, X_val_cie, y_val_cie, lr, 1000)\n",
        "    model_mat = linear_regression_sklearn(X_train_mat, y_train_mat, X_val_mat, y_val_mat, lr, 1000)\n",
        "    model_lp = linear_regression_sklearn(X_train_lp, y_train_lp, X_val_lp, y_val_lp, lr, 1000)\n",
        "    print(model_cie.score(X_val_cie, y_val_cie))\n",
        "    print(model_mat.score(X_val_mat, y_val_mat))\n",
        "    print(model_lp.score(X_val_lp, y_val_lp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPl7jKgJPW6"
      },
      "source": [
        "\n",
        "3. (0.75 point) Sometimes, we need some more complex function to make good prediction. Devise and evaluate a Polynomial Linear Regression model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GjGbg41PMHR9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.9240610146477337e+21\n",
            "-8.074752193926429e+19\n",
            "-5.673740135754602e+18\n"
          ]
        }
      ],
      "source": [
        "# TODO: Complex model. You can use scikit-learn libraries.\n",
        "\"\"\"Multi polynomial regression\"\"\"\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "def polynomial_regression(X_train, y_train, X_val, y_val, degree):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "model_cie = polynomial_regression(X_train_cie, y_train_cie, X_val_cie, y_val_cie, 2)\n",
        "model_mat = polynomial_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat, 2)\n",
        "model_lp = polynomial_regression(X_train_lp, y_train_lp, X_val_lp, y_val_lp, 2)\n",
        "print(model_cie.score(X_val_cie, y_val_cie))\n",
        "print(model_mat.score(X_val_mat, y_val_mat))\n",
        "print(model_lp.score(X_val_lp, y_val_lp))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBLKtosaLaCw"
      },
      "source": [
        "*texto em itálico*\n",
        " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldSh1vtWK5Zk"
      },
      "source": [
        "4. (0.5) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "mg7aNkl_LG4P"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: Plot the cost function vs. number of iterations in the training set.\n",
        "\n",
        "def plot_cost_function(train_loss,   title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_loss, label='train loss')\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_cost_function(train_loss_cie,  'Science')\n",
        "plot_cost_function(train_loss_mat,  'Math')\n",
        "plot_cost_function(train_loss_lp,  'Portuguese')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CfR862UoK9j6"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (449369750.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [46]\u001b[0;36m\u001b[0m\n\u001b[0;31m    *texto em itálico*\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "*texto em itálico*\n",
        "> What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xij-E5UUseS"
      },
      "source": [
        "5. (0.25 point) Pick **your best model**, based on your validation set, and predict the target values for the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_PobUahUseS"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Remove the columns used as target in the linear regression\"\"\"\n",
        "def tranform_into_log_reg(df):\n",
        "    df = df.drop(columns=['porc_ACERT_lp',\n",
        "       'porc_ACERT_MAT', 'porc_ACERT_CIE'], axis=1)\n",
        "    return df\n",
        "df = tranform_into_log_reg(df)\n",
        "type(df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
              "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
              "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31',\n",
              "       'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41',\n",
              "       'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50', 'Q51',\n",
              "       'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60', 'Q61',\n",
              "       'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C',\n",
              "       'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_log = df\n",
        "type(df_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['CD_ALUNO'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 76\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y162sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_log\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mCD_ALUNO\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y162sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mcolumns\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4955\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4956\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4957\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4958\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4959\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4960\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4961\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4962\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['CD_ALUNO'] not found in axis\""
          ]
        }
      ],
      "source": [
        "df_log.drop(columns=['CD_ALUNO'], axis=1, inplace=True)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(df, target, validation_size):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    return train_test_split(X, y, test_size=validation_size, random_state=42)\n",
        "X_train_cie, X_val_cie, y_train_cie, y_val_cie = split_data(df_log, 'nivel_profic_cie', 0.2)\n",
        "X_train_mat, X_val_mat, y_train_mat, y_val_mat = split_data(df_log, 'nivel_profic_mat', 0.2)\n",
        "X_train_lp, X_val_lp, y_train_lp, y_val_lp = split_data(df_log, 'nivel_profic_lp', 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df)\n",
        "    return scaler.transform(df)\n",
        "X_train_cie = normalize_data(X_train_cie)\n",
        "X_val_cie = normalize_data(X_val_cie)\n",
        "X_train_mat = normalize_data(X_train_mat)\n",
        "X_val_mat = normalize_data(X_val_mat)\n",
        "X_train_lp = normalize_data(X_train_lp)\n",
        "X_val_lp = normalize_data(X_val_lp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train_cie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCJuwjrAUseS"
      },
      "source": [
        "Now, this part of the assignment aims to predict students' proeficiency level on Portuguese, Mathematics, and Natural Sciences (target values: `nivel_profic_lp`, `nivel_profic_mat` and `nivel_profic_cie`) based on their socioeconomic data. Then, you have to **drop the columns `porc_ACERT_lp`,  `porc_ACERT_MAT`** and  **`porc_ACERT_CIE`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joYtn8avUseS"
      },
      "source": [
        "### Activities\n",
        "\n",
        "1. (2.75 points) Perform Multinomial Logistic Regression (_i.e._, softmax regression). It is a generalization of Logistic Regression to the case where we want to handle multiple classes. Try different combinations of features, dropping the ones less correlated to the target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-36Dt2V_UseT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Science\n",
            "LogisticRegression(max_iter=1000, multi_class='multinomial', solver='sag')\n",
            "Accuracy:  0.6312100854275524\n",
            "Math\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 82\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m, model_cie\u001b[39m.\u001b[39mscore(X_val_cie, y_val_cie))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMath\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model_mat \u001b[39m=\u001b[39m multinomial_logistic_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m, model_mat\u001b[39m.\u001b[39mscore(X_val_mat, y_val_mat))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPortuguese\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 82\u001b[0m in \u001b[0;36mmultinomial_logistic_regression\u001b[0;34m(X_train, y_train, X_val, y_val, num_epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultinomial_logistic_regression\u001b[39m(X_train, y_train, X_val, y_val, num_epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model \u001b[39m=\u001b[39m LogisticRegression(multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultinomial\u001b[39m\u001b[39m'\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m, max_iter\u001b[39m=\u001b[39m num_epochs)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y134sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[1;32m   1593\u001b[0m )(\n\u001b[1;32m   1594\u001b[0m     path_func(\n\u001b[1;32m   1595\u001b[0m         X,\n\u001b[1;32m   1596\u001b[0m         y,\n\u001b[1;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1615\u001b[0m )\n\u001b[1;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:864\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    861\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[1;32m    862\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[0;32m--> 864\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[1;32m    865\u001b[0m         X,\n\u001b[1;32m    866\u001b[0m         target,\n\u001b[1;32m    867\u001b[0m         sample_weight,\n\u001b[1;32m    868\u001b[0m         loss,\n\u001b[1;32m    869\u001b[0m         alpha,\n\u001b[1;32m    870\u001b[0m         beta,\n\u001b[1;32m    871\u001b[0m         max_iter,\n\u001b[1;32m    872\u001b[0m         tol,\n\u001b[1;32m    873\u001b[0m         verbose,\n\u001b[1;32m    874\u001b[0m         random_state,\n\u001b[1;32m    875\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    876\u001b[0m         max_squared_sum,\n\u001b[1;32m    877\u001b[0m         warm_start_sag,\n\u001b[1;32m    878\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    879\u001b[0m     )\n\u001b[1;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    883\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[1;32m    885\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:327\u001b[0m, in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    326\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[0;32m--> 327\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[1;32m    328\u001b[0m     dataset,\n\u001b[1;32m    329\u001b[0m     coef_init,\n\u001b[1;32m    330\u001b[0m     intercept_init,\n\u001b[1;32m    331\u001b[0m     n_samples,\n\u001b[1;32m    332\u001b[0m     n_features,\n\u001b[1;32m    333\u001b[0m     n_classes,\n\u001b[1;32m    334\u001b[0m     tol,\n\u001b[1;32m    335\u001b[0m     max_iter,\n\u001b[1;32m    336\u001b[0m     loss,\n\u001b[1;32m    337\u001b[0m     step_size,\n\u001b[1;32m    338\u001b[0m     alpha_scaled,\n\u001b[1;32m    339\u001b[0m     beta_scaled,\n\u001b[1;32m    340\u001b[0m     sum_gradient_init,\n\u001b[1;32m    341\u001b[0m     gradient_memory_init,\n\u001b[1;32m    342\u001b[0m     seen_init,\n\u001b[1;32m    343\u001b[0m     num_seen_init,\n\u001b[1;32m    344\u001b[0m     fit_intercept,\n\u001b[1;32m    345\u001b[0m     intercept_sum_gradient,\n\u001b[1;32m    346\u001b[0m     intercept_decay,\n\u001b[1;32m    347\u001b[0m     is_saga,\n\u001b[1;32m    348\u001b[0m     verbose,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[1;32m    352\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    355\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: Multinomial Logistic Regression. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def multinomial_logistic_regression(X_train, y_train, X_val, y_val, num_epochs = 1000):\n",
        "    model = LogisticRegression(multi_class='multinomial', solver='sag', max_iter= num_epochs)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "print(\"Science\")\n",
        "model_cie = multinomial_logistic_regression(X_train_cie, y_train_cie, X_val_cie, y_val_cie)\n",
        "print(\"Accuracy: \", model_cie.score(X_val_cie, y_val_cie))\n",
        "print(\"Math\")\n",
        "model_mat = multinomial_logistic_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat)\n",
        "print(\"Accuracy: \", model_mat.score(X_val_mat, y_val_mat))\n",
        "print(\"Portuguese\")\n",
        "model_lp = multinomial_logistic_regression(X_train_lp, y_train_lp, X_val_lp, y_val_lp)\n",
        "print(\"Accuracy: \", model_lp.score(X_val_lp, y_val_lp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQj3oImUUseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb1KNEqLUseT"
      },
      "source": [
        "2. (0.5 point) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfECeHi3UseT"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot the cost function vs. number of iterations in the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IM4mx23UseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqlv9-6OUseT"
      },
      "source": [
        "3. (0.75 point) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jdyJuS0UseT"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot the confusion matrix. You can use scikit-learn, seaborn, matplotlib libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAmCj0cpUseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdSGS4brHnAi"
      },
      "source": [
        "## Deadline\n",
        "\n",
        "Monday, September 19, 11:59 pm. \n",
        "\n",
        "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
        "- September 20, 11:59 pm : grade * 0.75\n",
        "- September 21, 11:59 pm : grade * 0.5\n",
        "- September 22, 11:59 pm : grade * 0.25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joN9pvZJIfW5"
      },
      "source": [
        "## Submission\n",
        "\n",
        "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
        "\n",
        "**This activity is NOT individual, it must be done in pairs (two-person group).**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
