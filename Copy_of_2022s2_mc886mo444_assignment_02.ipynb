{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs9E_R5yD48u"
      },
      "source": [
        "# **Assignment \\#2**: Machine Learning MC886/MO444\n",
        "University of Campinas (UNICAMP), Institute of Computing (IC)\n",
        "\n",
        "Prof. Sandra Avila, 2022s2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFS9Oum_RJX9",
        "outputId": "45094cce-bb6b-4ad6-966e-434b6c7b9db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RA1: 213259 Arthur Baia\n",
            "RA2: 200025 José Afonso\n"
          ]
        }
      ],
      "source": [
        "# TODO: RA & Name\n",
        "print(f'RA1: 213259 ' + 'Arthur Baia')\n",
        "print(f'RA2: 200025 ' + 'José Afonso')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVGH2s7fD_03"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Explore **linear regression** and **logistic regression** alternatives and come up with the best possible model for the problems, avoiding overfitting. In particular, predict the performance of students from public schools in the state of São Paulo based on socioeconomic data from SARESP (School Performance Assessment System of the State of São Paulo, or Sistema de Avaliação de Rendimento Escolar do Estado de São Paulo) 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3XDZRGqEwsk"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "These data were aggregated from [Open Data Platform of the Secretary of Education of the State of São Paulo](https://dados.educacao.sp.gov.br/) (*Portal de Dados Abertos da Secretaria da Educação do Estado de São Paulo*). The dataset is based on two data sources: [SARESP questionnaire](https://dados.educacao.sp.gov.br/dataset/question%C3%A1rios-saresp) and [SARESP test](https://dados.educacao.sp.gov.br/dataset/profici%C3%AAncia-do-sistema-de-avalia%C3%A7%C3%A3o-de-rendimento-escolar-do-estado-de-s%C3%A3o-paulo-saresp-por), conducted in 2021 with students from the 5th and 9th year of Primary School and 3rd year of Highschool. The questionnaire comprehends 63 socio-economical questions, and it is available at the [link](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing)), and the test is composed of questions of Portuguese, Mathematics, and Natural Sciences.\n",
        "\n",
        "\n",
        "**Data Dictionary**:\n",
        "\n",
        "- **CD_ALUNO**: Student ID;\n",
        "\n",
        "- **CODESC**: School ID;\n",
        "\n",
        "- **NOMESC**: School Name;\n",
        "\n",
        "- **RegiaoMetropolitana**: Metropolitan region;\n",
        "\n",
        "- **DE**: Name of the Education Board;\n",
        "\n",
        "- **CODMUN**: City ID;\n",
        "\n",
        "- **MUN**: City name;\n",
        "\n",
        "- **SERIE_ANO**: Scholar year;\n",
        "\n",
        "- **TURMA**: Class;\n",
        "\n",
        "- **TP_SEXO**: Sex (Female/Male);\n",
        "\n",
        "- **DT_NASCIMENTO**: Birth date;\n",
        "\n",
        "- **PERIODO**: Period of study (morning, afternoon, evening);\n",
        "\n",
        "- **Tem_Nec**: Whether student has any special needs (1 = yes, 0 = no);\n",
        "\n",
        "- **NEC_ESP_1** - **NEC_ESP_5**: Student disabilities;\n",
        "\n",
        "- **Tipo_PROVA**: Exam type (A = Enlarged, B = Braile, C = Common);\n",
        "\n",
        "- **QN**: Student answer to the question N (N= 1, ... , 63), see  questions in [questionnaire](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing));\n",
        "\n",
        "- **porc_ACERT_lp**: Percentage of correct answers in the Portuguese test;\n",
        "\n",
        "- **porc_ACERT_MAT**: Percentage of correct answers in the Mathematics test;\n",
        "\n",
        "- **porc_ACERT_CIE**: Percentage of correct answers in the Natural Sciences test;\n",
        "\n",
        "- **nivel_profic_lp**: Proficiency level in the Portuguese test;\n",
        "\n",
        "- **nivel_profic_mat**: Proficiency level in the Mathematics test;\n",
        "\n",
        "- **nivel_profic_cie**:  Proficiency level in the Natural Sciences test.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "You must respect the following training/test split:\n",
        "- SARESP_train.csv\n",
        "- SARESP_test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FAA8hsZUseO"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "This part of the assignment aims to predict students' performance on Portuguese, Mathematics, and Natural Sciences tests (target values: `porc_ACERT_lp`, `porc_ACERT_MAT`, and  `porc_ACERT_CIE`) based on their socioeconomic data. Then, at this point, you have to **drop the columns `nivel_profic_lp`, `nivel_profic_mat`** and **`nivel_profic_cie`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d495CmpCltx"
      },
      "source": [
        "### Activities\n",
        "\n",
        "1. (3.5 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org). Keep in mind that friends don't let friends use testing data for training :-)\n",
        "\n",
        "Note: Before we start an ML project, we always conduct a brief exploratory analysis :D \n",
        "\n",
        "Some factors to consider: Are there any outliers? Are there missing values? How will you handle categorical variables? Are there any features with low correlation with the target variables? What happens if you drop them?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Step 1: Load data and check it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y0QxxH1KgE1",
        "outputId": "c80087fa-d4a6-4cfb-dbb8-e0ff167ae8f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5077/1712878385.py:9: DtypeWarning: Columns (78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"SARESP_train.csv\")\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load and preprocess your dataset.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"SARESP_train.csv\")\n",
        "df_teste = pd.read_csv(\"SARESP_test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "DAADl99uoJp1",
        "outputId": "aecc2d5c-d89c-4b7f-c957-cfe195d94a0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>NOMESC</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>...</th>\n",
              "      <th>NEC_ESP_4</th>\n",
              "      <th>NEC_ESP_5</th>\n",
              "      <th>Tipo_PROVA</th>\n",
              "      <th>Tem_Nec</th>\n",
              "      <th>porc_ACERT_lp</th>\n",
              "      <th>porc_ACERT_MAT</th>\n",
              "      <th>porc_ACERT_CIE</th>\n",
              "      <th>nivel_profic_lp</th>\n",
              "      <th>nivel_profic_mat</th>\n",
              "      <th>nivel_profic_cie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26270013</td>\n",
              "      <td>JULIO FORTES</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>41.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>20.8</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30756614</td>\n",
              "      <td>MESSIAS FREIRE PROFESSOR</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>83.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.7</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Avançado</td>\n",
              "      <td>Adequado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26014872</td>\n",
              "      <td>JOSE CONTI</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>58.3</td>\n",
              "      <td>37.5</td>\n",
              "      <td>54.2</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25739025</td>\n",
              "      <td>NAPOLEAO DE CARVALHO FREIRE PROFESSOR</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>29.2</td>\n",
              "      <td>29.2</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27363009</td>\n",
              "      <td>RESIDENCIAL BORDON</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>79.2</td>\n",
              "      <td>41.7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120591</th>\n",
              "      <td>28799794</td>\n",
              "      <td>ENNIO CHIESA PROFESSOR</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>79.2</td>\n",
              "      <td>66.7</td>\n",
              "      <td>83.3</td>\n",
              "      <td>Adequado</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Adequado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120592</th>\n",
              "      <td>27825068</td>\n",
              "      <td>HELIO HELENE</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120593</th>\n",
              "      <td>23873470</td>\n",
              "      <td>ALBERTO SANTOS DUMONT</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>41.7</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120594</th>\n",
              "      <td>31376275</td>\n",
              "      <td>FRANCISCO BONFIM</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>45.8</td>\n",
              "      <td>70.8</td>\n",
              "      <td>54.2</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120595</th>\n",
              "      <td>28109335</td>\n",
              "      <td>MAGDALENA SANSEVERINO GROSSO PROFESSORA</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>37.5</td>\n",
              "      <td>16.7</td>\n",
              "      <td>16.7</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "      <td>Abaixo do Básico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120596 rows × 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        CD_ALUNO                                   NOMESC Q1 Q2 Q3 Q4 Q5 Q6  \\\n",
              "0       26270013                             JULIO FORTES  B  E  E  E  E  E   \n",
              "1       30756614                 MESSIAS FREIRE PROFESSOR  B  D  E  C  E  E   \n",
              "2       26014872                               JOSE CONTI  B  E  B  D  E  B   \n",
              "3       25739025    NAPOLEAO DE CARVALHO FREIRE PROFESSOR  B  D  E  D  C  E   \n",
              "4       27363009                       RESIDENCIAL BORDON  B  D  E  E  E  E   \n",
              "...          ...                                      ... .. .. .. .. .. ..   \n",
              "120591  28799794                   ENNIO CHIESA PROFESSOR  A  E  E  E  E  E   \n",
              "120592  27825068                             HELIO HELENE  B  D  D  D  D  D   \n",
              "120593  23873470                    ALBERTO SANTOS DUMONT  A  E  E  E  E  E   \n",
              "120594  31376275                         FRANCISCO BONFIM  B  E  C  C  D  B   \n",
              "120595  28109335  MAGDALENA SANSEVERINO GROSSO PROFESSORA  A  A  A  A  A  A   \n",
              "\n",
              "       Q7 Q8  ... NEC_ESP_4 NEC_ESP_5 Tipo_PROVA Tem_Nec porc_ACERT_lp  \\\n",
              "0       E  E  ...       NaN       NaN          C       0          41.7   \n",
              "1       E  E  ...       NaN       NaN          C       0          83.3   \n",
              "2       D  C  ...       NaN       NaN          C       0          58.3   \n",
              "3       D  D  ...       NaN       NaN          C       0          29.2   \n",
              "4       E  C  ...       NaN       NaN          C       0          79.2   \n",
              "...    .. ..  ...       ...       ...        ...     ...           ...   \n",
              "120591  E  E  ...       NaN       NaN          C       0          79.2   \n",
              "120592  D  D  ...       NaN       NaN          C       0          37.5   \n",
              "120593  D  D  ...       NaN       NaN          C       0          50.0   \n",
              "120594  B  A  ...       NaN       NaN          C       1          45.8   \n",
              "120595  A  A  ...       NaN       NaN          C       1          37.5   \n",
              "\n",
              "       porc_ACERT_MAT porc_ACERT_CIE   nivel_profic_lp  nivel_profic_mat  \\\n",
              "0                20.8           20.8  Abaixo do Básico  Abaixo do Básico   \n",
              "1               100.0           66.7          Adequado          Avançado   \n",
              "2                37.5           54.2            Básico            Básico   \n",
              "3                29.2           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "4                41.7           50.0          Adequado  Abaixo do Básico   \n",
              "...               ...            ...               ...               ...   \n",
              "120591           66.7           83.3          Adequado            Básico   \n",
              "120592           25.0           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "120593           37.5           41.7            Básico  Abaixo do Básico   \n",
              "120594           70.8           54.2  Abaixo do Básico            Básico   \n",
              "120595           16.7           16.7  Abaixo do Básico  Abaixo do Básico   \n",
              "\n",
              "        nivel_profic_cie  \n",
              "0       Abaixo do Básico  \n",
              "1               Adequado  \n",
              "2                 Básico  \n",
              "3       Abaixo do Básico  \n",
              "4                 Básico  \n",
              "...                  ...  \n",
              "120591          Adequado  \n",
              "120592  Abaixo do Básico  \n",
              "120593  Abaixo do Básico  \n",
              "120594  Abaixo do Básico  \n",
              "120595  Abaixo do Básico  \n",
              "\n",
              "[120596 rows x 88 columns]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePztAuVOoMe1",
        "outputId": "bbde7cd6-825a-4234-ea16-40b77629606e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>CODMUN</th>\n",
              "      <th>CODESC</th>\n",
              "      <th>NEC_ESP_5</th>\n",
              "      <th>Tem_Nec</th>\n",
              "      <th>porc_ACERT_lp</th>\n",
              "      <th>porc_ACERT_MAT</th>\n",
              "      <th>porc_ACERT_CIE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205960e+05</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.734087e+07</td>\n",
              "      <td>364.349075</td>\n",
              "      <td>279415.870510</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.019818</td>\n",
              "      <td>60.151213</td>\n",
              "      <td>52.225829</td>\n",
              "      <td>56.928877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.946464e+06</td>\n",
              "      <td>220.098318</td>\n",
              "      <td>394245.824543</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.139376</td>\n",
              "      <td>21.730825</td>\n",
              "      <td>21.262466</td>\n",
              "      <td>18.441383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.739548e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.529711e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>15568.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.700000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>45.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.712102e+07</td>\n",
              "      <td>336.000000</td>\n",
              "      <td>35178.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>58.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.910558e+07</td>\n",
              "      <td>582.000000</td>\n",
              "      <td>901573.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.200000</td>\n",
              "      <td>66.700000</td>\n",
              "      <td>70.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.796186e+07</td>\n",
              "      <td>793.000000</td>\n",
              "      <td>926103.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD_ALUNO         CODMUN         CODESC  NEC_ESP_5        Tem_Nec  \\\n",
              "count  1.205960e+05  120596.000000  120596.000000        0.0  120596.000000   \n",
              "mean   2.734087e+07     364.349075  279415.870510        NaN       0.019818   \n",
              "std    2.946464e+06     220.098318  394245.824543        NaN       0.139376   \n",
              "min    1.739548e+07     100.000000      24.000000        NaN       0.000000   \n",
              "25%    2.529711e+07     100.000000   15568.000000        NaN       0.000000   \n",
              "50%    2.712102e+07     336.000000   35178.000000        NaN       0.000000   \n",
              "75%    2.910558e+07     582.000000  901573.000000        NaN       0.000000   \n",
              "max    3.796186e+07     793.000000  926103.000000        NaN       1.000000   \n",
              "\n",
              "       porc_ACERT_lp  porc_ACERT_MAT  porc_ACERT_CIE  \n",
              "count  120596.000000   120596.000000   120596.000000  \n",
              "mean       60.151213       52.225829       56.928877  \n",
              "std        21.730825       21.262466       18.441383  \n",
              "min         0.000000        0.000000        0.000000  \n",
              "25%        41.700000       37.500000       45.800000  \n",
              "50%        62.500000       50.000000       58.300000  \n",
              "75%        79.200000       66.700000       70.800000  \n",
              "max       100.000000      100.000000      100.000000  "
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvxhHEeSpaW0",
        "outputId": "7820214f-75cb-4153-bd20-19b11ec475d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'Q63', 'RegiaoMetropolitana', 'DE',\n",
              "       'CODMUN', 'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO',\n",
              "       'DT_NASCIMENTO', 'PERIODO', 'NEC_ESP_1', 'NEC_ESP_2', 'NEC_ESP_3',\n",
              "       'NEC_ESP_4', 'NEC_ESP_5', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Step 2: Check NaNs in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUu_-HXQs_tb",
        "outputId": "9578fccd-4ac9-4664-a6b4-021b02a17856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NEC_ESP_5           120596\n",
              "NEC_ESP_4           120595\n",
              "NEC_ESP_3           120520\n",
              "NEC_ESP_2           120489\n",
              "NEC_ESP_1           118206\n",
              "                     ...  \n",
              "Q26                      0\n",
              "Q25                      0\n",
              "Q24                      0\n",
              "Q23                      0\n",
              "nivel_profic_cie         0\n",
              "Length: 88, dtype: int64"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum(axis=0).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there are a lot of NaN's in the NEC_ESP columns, they will be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'Q63', 'RegiaoMetropolitana', 'DE',\n",
              "       'CODMUN', 'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO',\n",
              "       'DT_NASCIMENTO', 'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp',\n",
              "       'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def drop_nec_columns(df):\n",
        "    for i in range(1, 6):\n",
        "        df.drop(columns=[f'NEC_ESP_{i}'], inplace=True)\n",
        "drop_nec_columns(df)\n",
        "drop_nec_columns(df_teste)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Step 3: Transform data\n",
        "\n",
        "Based on the questions {Q0, .., Q63} and their meaning and possible values, it's needed to transform them into numerical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'NOMESC', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
              "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
              "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
              "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
              "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48',\n",
              "       'Q49', 'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58',\n",
              "       'Q59', 'Q60', 'Q61', 'Q62', 'RegiaoMetropolitana', 'DE', 'CODMUN',\n",
              "       'MUN', 'CODESC', 'SERIE_ANO', 'TURMA', 'TP_SEXO', 'DT_NASCIMENTO',\n",
              "       'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'nivel_profic_lp', 'nivel_profic_mat',\n",
              "       'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def question_map(df):\n",
        "\n",
        "    ordinal_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n",
        "    inversed_ordinal_map = {'A': 5, 'B': 4, 'C': 3, 'D': 2, 'E': 1}\n",
        "    dont_know_ordinal_map = {'A': 1, 'B': 2, 'C': 3, 'D': 1, 'E': 2}\n",
        "    inversed_dont_know_ordinal_map = {'A': 4, 'B': 3, 'C': 2, 'D': 1, 'E': 2} #applied penalty for don't know anwser\n",
        "    home_ordinal_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
        "    miss_someone_map = {'A': 1, 'B': 1, 'C': 1, 'D': 0}\n",
        "    someone_helped_map = {'A': 2, 'B': 1, 'C': 1, 'D': 0}\n",
        "\n",
        "    for q in range(1, 64):\n",
        "        if (q <= 8 or (q > 26 and q <= 33) or (q > 33 and q <= 41) or (q > 56 and q <= 58) or q == 60): #ordinal map\n",
        "            df.replace({f'Q{q}': ordinal_map}, inplace=True)\n",
        "        elif ((q > 8 and q <= 26) or q == 59):\n",
        "            df.replace({f'Q{q}': inversed_ordinal_map}, inplace=True) \n",
        "        elif (q == 42):\n",
        "            df.replace({f'Q{q}': inversed_dont_know_ordinal_map}, inplace=True)\n",
        "        elif (q > 42 and q <= 49):\n",
        "            df.replace({f'Q{q}': dont_know_ordinal_map}, inplace=True)\n",
        "        elif (q > 49 and q <= 56):\n",
        "            df.replace({f'Q{q}': home_ordinal_map}, inplace=True)\n",
        "        elif (q == 61):\n",
        "            df.replace({f'Q{q}': miss_someone_map}, inplace=True)\n",
        "        elif (q == 62):\n",
        "            df.replace({f'Q{q}': someone_helped_map}, inplace=True)\n",
        "        else: # 63 question\n",
        "            df = pd.concat([df, pd.get_dummies(df['Q63'], prefix='Q63')], axis=1)\n",
        "            df.drop(columns=[ 'Q63'], inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = question_map(df)\n",
        "df_teste = question_map(df_teste)\n",
        "df.columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Considering there are many columns related to geographical columns, { 'RegiaoMetropolitana', 'DE', 'CODMUN', 'MUN', 'CODESC' }, we will select only one column related to this \n",
        "matter, because there are no indicator related to social geographical like HDI to correlate to them. Also, if we one hot encode each of these columns there will be a huge increase in dimensionality. So, we will choose the 'Regiao metropolitana' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RegiaoMetropolitana\n",
              "Interior                                                   39211\n",
              "Região Metropolitana da Baixada Santista                    7688\n",
              "Região Metropolitana de Campinas                            3465\n",
              "Região Metropolitana de Ribeirão Preto                      6712\n",
              "Região Metropolitana de Sorocaba                            6736\n",
              "Região Metropolitana de São Paulo                          47437\n",
              "Região Metropolitana do Vale do Paraíba e Litoral Norte     9347\n",
              "Name: RegiaoMetropolitana, dtype: int64"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['RegiaoMetropolitana'].groupby(df['RegiaoMetropolitana']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_geo(df):\n",
        "    df = pd.concat([df, pd.get_dummies(df['RegiaoMetropolitana'], prefix='RegiaoMetropolitana')], axis=1)\n",
        "    df.drop(columns=['NOMESC', 'MUN', 'CODESC', 'CODMUN', 'RegiaoMetropolitana',  'DE'], inplace=True)\n",
        "    return df\n",
        "df = select_geo(df)\n",
        "df_teste = select_geo(df_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D',\n",
              "       'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df._get_numeric_data().columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nivel_profic_lp'}"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_categorical_columns(df):\n",
        "    cols = df.columns\n",
        "\n",
        "    num_cols = df._get_numeric_data().columns\n",
        "\n",
        "    return list(set(cols) - set(num_cols))\n",
        "set(get_categorical_columns(df)) - set(get_categorical_columns(df_teste))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TURMA', 'TP_SEXO', 'DT_NASCIMENTO',\n",
              "       'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'nivel_profic_lp', 'nivel_profic_mat',\n",
              "       'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C', 'Q63_D',\n",
              "       'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TURMA', 'TP_SEXO', 'DT_NASCIMENTO',\n",
              "       'PERIODO', 'Tipo_PROVA', 'Tem_Nec', 'porc_ACERT_lp', 'porc_ACERT_MAT',\n",
              "       'porc_ACERT_CIE', 'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A',\n",
              "       'Q63_B', 'Q63_C', 'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_teste.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since birth date is not a numerical category, we turn it into age (idade column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         18\n",
              "1         12\n",
              "2         15\n",
              "3         18\n",
              "4         15\n",
              "          ..\n",
              "120591    16\n",
              "120592    13\n",
              "120593    19\n",
              "120594    12\n",
              "120595    17\n",
              "Name: idade, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "def calculate_age(born):\n",
        "    born = datetime.strptime(born, \"%m/%d/%Y\").date()\n",
        "    today = date.today()\n",
        "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
        "\n",
        "\n",
        "df['idade'] = df['DT_NASCIMENTO'].apply(calculate_age)\n",
        "df_teste['idade'] = df_teste['DT_NASCIMENTO'].apply(calculate_age)\n",
        "df = df.drop(columns=['DT_NASCIMENTO'])\n",
        "df_teste = df_teste.drop(columns=['DT_NASCIMENTO'])\n",
        "df['idade']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='idade'>"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['idade'].groupby(df['idade']).count().plot(kind='bar')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mapping categorical features into numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sex_mapper(df):\n",
        "    sex_map = {'F': 0, 'M': 1}\n",
        "    df.replace({'TP_SEXO': sex_map}, inplace=True)\n",
        "    return df\n",
        "df = sex_mapper(df)\n",
        "df_teste = sex_mapper(df_teste)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since more years of schooling may mean more knowledge, we will choose to make SERIE_ANO as ordinal as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         3\n",
              "1         1\n",
              "2         2\n",
              "3         3\n",
              "4         2\n",
              "         ..\n",
              "120591    2\n",
              "120592    1\n",
              "120593    3\n",
              "120594    1\n",
              "120595    2\n",
              "Name: SERIE_ANO, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def school_year_mapper(df): \n",
        "    school_year_map = {'EM-3ª série': 3, '9º Ano EF': 2, '5º Ano EF': 1}\n",
        "    df.replace({'SERIE_ANO': school_year_map}, inplace=True)\n",
        "    return df\n",
        "df = school_year_mapper(df)\n",
        "df_teste = school_year_mapper(df_teste)\n",
        "df['SERIE_ANO']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Drop column TURMA, since in large scale it is not relevant\"\"\"\n",
        "def drop_turma(df):\n",
        "    df = df.drop(columns=['TURMA'])\n",
        "    return df\n",
        "\n",
        "df = drop_turma(df)\n",
        "df_teste = drop_turma(df_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A'}"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Get unique values for column Tipo Prova\"\"\"\n",
        "set(df['Tipo_PROVA'].unique()) - set(df_teste['Tipo_PROVA'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Since there is just one value in test and two values in train, we can drop this column\n",
        "def drop_tipo_prova(df):\n",
        "    df = df.drop(columns=['Tipo_PROVA'])\n",
        "    return df\n",
        "df = drop_tipo_prova(df)\n",
        "df_teste = drop_tipo_prova(df_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'PERIODO'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'PERIODO'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPERIODO\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m one_hot_encoding_(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_teste \u001b[39m=\u001b[39m one_hot_encoding_(df_teste)\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 35\u001b[0m in \u001b[0;36mone_hot_encoding_\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mone_hot_encoding_\u001b[39m(df):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, pd\u001b[39m.\u001b[39mget_dummies(df[\u001b[39m'\u001b[39;49m\u001b[39mPERIODO\u001b[39;49m\u001b[39m'\u001b[39;49m], prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPERIODO\u001b[39m\u001b[39m'\u001b[39m)], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPERIODO\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'PERIODO'"
          ]
        }
      ],
      "source": [
        "\"\"\"One hot encoding on the columns PERIODO, Tipo_PROVA\"\"\"\n",
        "def one_hot_encoding_(df):\n",
        "    df = pd.concat([df, pd.get_dummies(df['PERIODO'], prefix='PERIODO')], axis=1)\n",
        "    df = df.drop(columns=['PERIODO'])\n",
        "    return df\n",
        "df = one_hot_encoding_(df)\n",
        "df_teste = one_hot_encoding_(df_teste)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SERIE_ANO']"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_categorical_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nivel_profic_mat', 'nivel_profic_cie', 'SERIE_ANO', 'Tipo_PROVA']"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_categorical_columns(df_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Abaixo do Básico' 'Avançado' 'Básico' 'Adequado']\n",
            "['Abaixo do Básico' 'Adequado' 'Básico' 'Avançado']\n",
            "['Abaixo do Básico' 'Adequado' 'Básico' 'Avançado']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Get unique values of nivel_profic_mat\"\"\"\n",
        "print(df['nivel_profic_mat'].unique())\n",
        "print(df['nivel_profic_lp'].unique())\n",
        "print(df['nivel_profic_cie'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         0\n",
              "1         3\n",
              "2         1\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "120591    1\n",
              "120592    0\n",
              "120593    0\n",
              "120594    1\n",
              "120595    0\n",
              "Name: nivel_profic_mat, Length: 120596, dtype: int64"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def map_categorical_columns_for_log_reg(df):\n",
        "    \"\"\"Map the categorical columns to numerical values\"\"\"\n",
        "    map_for_log_reg = { 'Abaixo do Básico': 0, 'Adequado': 2, 'Básico': 1, 'Avançado': 3}\n",
        "    df.replace({'nivel_profic_mat': map_for_log_reg}, inplace=True)\n",
        "    df.replace({'nivel_profic_lp': map_for_log_reg}, inplace=True)\n",
        "    df.replace({'nivel_profic_cie': map_for_log_reg}, inplace=True)\n",
        "    return df\n",
        "map_categorical_columns_for_log_reg(df)\n",
        "map_categorical_columns_for_log_reg(df_teste)\n",
        "df['nivel_profic_mat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SERIE_ANO', 'Tipo_PROVA']"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_categorical_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the columns were rightly transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Step 4: With all the columns being numbers, we can start to perform numerical analysis such as correlation, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD_ALUNO</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>...</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana da Baixada Santista</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Campinas</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Sorocaba</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de São Paulo</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte</th>\n",
              "      <th>idade</th>\n",
              "      <th>PERIODO_MANHÃ</th>\n",
              "      <th>PERIODO_NOITE</th>\n",
              "      <th>PERIODO_TARDE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205960e+05</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "      <td>120596.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.734087e+07</td>\n",
              "      <td>1.803567</td>\n",
              "      <td>4.183397</td>\n",
              "      <td>4.234850</td>\n",
              "      <td>3.901249</td>\n",
              "      <td>3.994676</td>\n",
              "      <td>3.839248</td>\n",
              "      <td>4.015813</td>\n",
              "      <td>3.542456</td>\n",
              "      <td>4.551519</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063750</td>\n",
              "      <td>0.028732</td>\n",
              "      <td>0.055657</td>\n",
              "      <td>0.055856</td>\n",
              "      <td>0.393355</td>\n",
              "      <td>0.077507</td>\n",
              "      <td>15.748939</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.110169</td>\n",
              "      <td>0.207478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.946464e+06</td>\n",
              "      <td>0.634012</td>\n",
              "      <td>0.942674</td>\n",
              "      <td>1.032048</td>\n",
              "      <td>1.171602</td>\n",
              "      <td>1.033197</td>\n",
              "      <td>1.233479</td>\n",
              "      <td>1.100245</td>\n",
              "      <td>1.272283</td>\n",
              "      <td>0.723518</td>\n",
              "      <td>...</td>\n",
              "      <td>0.244308</td>\n",
              "      <td>0.167054</td>\n",
              "      <td>0.229259</td>\n",
              "      <td>0.229644</td>\n",
              "      <td>0.488496</td>\n",
              "      <td>0.267395</td>\n",
              "      <td>2.466573</td>\n",
              "      <td>0.465563</td>\n",
              "      <td>0.313102</td>\n",
              "      <td>0.405502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.739548e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.529711e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.712102e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.910558e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.796186e+07</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 86 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD_ALUNO             Q1             Q2             Q3  \\\n",
              "count  1.205960e+05  120596.000000  120596.000000  120596.000000   \n",
              "mean   2.734087e+07       1.803567       4.183397       4.234850   \n",
              "std    2.946464e+06       0.634012       0.942674       1.032048   \n",
              "min    1.739548e+07       1.000000       1.000000       1.000000   \n",
              "25%    2.529711e+07       1.000000       4.000000       4.000000   \n",
              "50%    2.712102e+07       2.000000       4.000000       5.000000   \n",
              "75%    2.910558e+07       2.000000       5.000000       5.000000   \n",
              "max    3.796186e+07       4.000000       5.000000       5.000000   \n",
              "\n",
              "                  Q4             Q5             Q6             Q7  \\\n",
              "count  120596.000000  120596.000000  120596.000000  120596.000000   \n",
              "mean        3.901249       3.994676       3.839248       4.015813   \n",
              "std         1.171602       1.033197       1.233479       1.100245   \n",
              "min         1.000000       1.000000       1.000000       1.000000   \n",
              "25%         3.000000       3.000000       3.000000       3.000000   \n",
              "50%         4.000000       4.000000       4.000000       4.000000   \n",
              "75%         5.000000       5.000000       5.000000       5.000000   \n",
              "max         5.000000       5.000000       5.000000       5.000000   \n",
              "\n",
              "                  Q8             Q9  ...  \\\n",
              "count  120596.000000  120596.000000  ...   \n",
              "mean        3.542456       4.551519  ...   \n",
              "std         1.272283       0.723518  ...   \n",
              "min         1.000000       3.000000  ...   \n",
              "25%         3.000000       4.000000  ...   \n",
              "50%         4.000000       5.000000  ...   \n",
              "75%         5.000000       5.000000  ...   \n",
              "max         5.000000       5.000000  ...   \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana da Baixada Santista  \\\n",
              "count                                      120596.000000              \n",
              "mean                                            0.063750              \n",
              "std                                             0.244308              \n",
              "min                                             0.000000              \n",
              "25%                                             0.000000              \n",
              "50%                                             0.000000              \n",
              "75%                                             0.000000              \n",
              "max                                             1.000000              \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Campinas  \\\n",
              "count                                      120596.000000      \n",
              "mean                                            0.028732      \n",
              "std                                             0.167054      \n",
              "min                                             0.000000      \n",
              "25%                                             0.000000      \n",
              "50%                                             0.000000      \n",
              "75%                                             0.000000      \n",
              "max                                             1.000000      \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto  \\\n",
              "count                                      120596.000000            \n",
              "mean                                            0.055657            \n",
              "std                                             0.229259            \n",
              "min                                             0.000000            \n",
              "25%                                             0.000000            \n",
              "50%                                             0.000000            \n",
              "75%                                             0.000000            \n",
              "max                                             1.000000            \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Sorocaba  \\\n",
              "count                                      120596.000000      \n",
              "mean                                            0.055856      \n",
              "std                                             0.229644      \n",
              "min                                             0.000000      \n",
              "25%                                             0.000000      \n",
              "50%                                             0.000000      \n",
              "75%                                             0.000000      \n",
              "max                                             1.000000      \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de São Paulo  \\\n",
              "count                                      120596.000000       \n",
              "mean                                            0.393355       \n",
              "std                                             0.488496       \n",
              "min                                             0.000000       \n",
              "25%                                             0.000000       \n",
              "50%                                             0.000000       \n",
              "75%                                             1.000000       \n",
              "max                                             1.000000       \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte  \\\n",
              "count                                      120596.000000                             \n",
              "mean                                            0.077507                             \n",
              "std                                             0.267395                             \n",
              "min                                             0.000000                             \n",
              "25%                                             0.000000                             \n",
              "50%                                             0.000000                             \n",
              "75%                                             0.000000                             \n",
              "max                                             1.000000                             \n",
              "\n",
              "               idade  PERIODO_MANHÃ  PERIODO_NOITE  PERIODO_TARDE  \n",
              "count  120596.000000  120596.000000  120596.000000  120596.000000  \n",
              "mean       15.748939       0.682353       0.110169       0.207478  \n",
              "std         2.466573       0.465563       0.313102       0.405502  \n",
              "min        10.000000       0.000000       0.000000       0.000000  \n",
              "25%        15.000000       0.000000       0.000000       0.000000  \n",
              "50%        16.000000       1.000000       0.000000       0.000000  \n",
              "75%        18.000000       1.000000       0.000000       0.000000  \n",
              "max        56.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 86 columns]"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120596, 88)"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outliers detection\n",
        "\n",
        "Since the noly original numerical columns were the porc_ACERT, we will only perform outlier detection on these. The method to find the outliers will be though z-score and standard deviation, it's known that 99% of data is located between -3 std to 3 std, with that in mind we will drop all the data the is beyond this range  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00024876446979999335\n",
            "0.0\n",
            "0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#removing outliers\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_CIE'])) > 3)])/len(df.index)) #less than 0.025%\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_MAT'])) > 3)])/len(df.index))\n",
        "print(len(df[(np.abs(stats.zscore(df['porc_ACERT_lp'])) > 3)])/len(df.index))\n",
        "\n",
        "df.boxplot(column=['porc_ACERT_lp',\n",
        "       'porc_ACERT_MAT', 'porc_ACERT_CIE'])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there are less than 0.025% of data that are outliers, there will be no great negative effects in dropping it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[(np.abs(stats.zscore(df['porc_ACERT_CIE'])) < 3)]\n",
        "type(df)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing df's for each specific target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cie = df \n",
        "df_mat = df\n",
        "df_lp = df\n",
        "df_cie_test = df_teste\n",
        "df_mat_test = df_teste\n",
        "df_lp_test = df_teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set()\n",
            "set()\n",
            "set()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tipo_PROVA', 'Tem_Nec',\n",
              "       'porc_ACERT_lp', 'porc_ACERT_MAT', 'porc_ACERT_CIE', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C',\n",
              "       'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(set(df_cie_test.columns) - set(df_cie.columns))\n",
        "print(set(df_mat_test.columns) - set(df_mat.columns))\n",
        "print(set(df_lp_test.columns) - set(df_lp.columns))\n",
        "df_mat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SERIE_ANO', 'Tipo_PROVA']\n",
            "['SERIE_ANO', 'Tipo_PROVA']\n",
            "['SERIE_ANO', 'Tipo_PROVA']\n",
            "['SERIE_ANO', 'Tipo_PROVA']\n",
            "['SERIE_ANO', 'Tipo_PROVA']\n",
            "['SERIE_ANO', 'Tipo_PROVA']\n"
          ]
        }
      ],
      "source": [
        "def tranform_into_lin_reg(df):\n",
        "    \"\"\"Drop all the categorical columns in the dataframe lin_reg_df\"\"\"\n",
        "    if 'nivel_profic_mat' in df.columns:\n",
        "        df = df.drop(columns=['nivel_profic_mat'])\n",
        "    if 'nivel_profic_lp' in df.columns:\n",
        "        df = df.drop(columns=['nivel_profic_lp'])\n",
        "    if 'nivel_profic_cie' in df.columns:\n",
        "        df = df.drop(columns=['nivel_profic_cie'])\n",
        "    return df\n",
        "\n",
        "\n",
        "df_cie_lr = tranform_into_lin_reg(df_cie)\n",
        "print(get_categorical_columns(df_cie_lr))\n",
        "df_mat_lr = tranform_into_lin_reg(df_mat)\n",
        "print(get_categorical_columns(df_mat_lr))\n",
        "df_lp_lr  = tranform_into_lin_reg(df_lp)\n",
        "print(get_categorical_columns(df_lp_lr))\n",
        "df_cie_lr_test = tranform_into_lin_reg(df_cie_test)\n",
        "print(get_categorical_columns(df_cie_lr_test))\n",
        "df_mat_lr_test = tranform_into_lin_reg(df_mat_test)\n",
        "print(get_categorical_columns(df_mat_lr_test))\n",
        "df_lp_lr_test = tranform_into_lin_reg(df_lp_test)\n",
        "print(get_categorical_columns(df_lp_lr_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tipo_PROVA', 'Tem_Nec',\n",
              "       'porc_ACERT_lp', 'porc_ACERT_MAT', 'porc_ACERT_CIE', 'Q63_A', 'Q63_B',\n",
              "       'Q63_C', 'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie_lr.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop CD_ALUNO\n",
        "df_cie_lr = df_cie_lr.drop(columns=['CD_ALUNO'])\n",
        "df_mat_lr = df_mat_lr.drop(columns=['CD_ALUNO'])\n",
        "df_lp_lr = df_lp_lr.drop(columns=['CD_ALUNO'])\n",
        "df_cie_lr_test = df_cie_lr_test.drop(columns=['CD_ALUNO'])\n",
        "df_mat_lr_test = df_mat_lr_test.drop(columns=['CD_ALUNO'])\n",
        "df_lp_lr_test = df_lp_lr_test.drop(columns=['CD_ALUNO'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Function to normalize the data\"\"\"\n",
        "def normalize_data(df):\n",
        "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df)\n",
        "    return scaler.transform(df)\n",
        "df_cie_lr = pd.DataFrame(normalize_data(df_cie_lr), columns=df_cie_lr.columns,index=df_cie_lr.index)\n",
        "df_mat_lr = pd.DataFrame(normalize_data(df_mat_lr), columns=df_mat_lr.columns,index=df_mat_lr.index)\n",
        "df_lp_lr = pd.DataFrame(normalize_data(df_lp_lr), columns=df_lp_lr.columns,index=df_lp_lr.index)\n",
        "df_cie_lr_test = pd.DataFrame(normalize_data(df_cie_lr_test), columns=df_cie_lr_test.columns,index=df_cie_lr_test.index)\n",
        "df_mat_lr_test = pd.DataFrame(normalize_data(df_mat_lr_test), columns=df_mat_lr_test.columns,index=df_mat_lr_test.index)\n",
        "df_lp_lr_test = pd.DataFrame(normalize_data(df_lp_lr_test), columns=df_lp_lr_test.columns,index=df_lp_lr_test.index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>...</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de Sorocaba</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana de São Paulo</th>\n",
              "      <th>RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte</th>\n",
              "      <th>idade</th>\n",
              "      <th>PERIODO_MANHÃ</th>\n",
              "      <th>PERIODO_NOITE</th>\n",
              "      <th>PERIODO_TARDE</th>\n",
              "      <th>Tipo_PROVA_A</th>\n",
              "      <th>Tipo_PROVA_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "      <td>1.205660e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.049024e-16</td>\n",
              "      <td>-4.315142e-16</td>\n",
              "      <td>-1.772732e-16</td>\n",
              "      <td>1.222584e-16</td>\n",
              "      <td>-7.637836e-17</td>\n",
              "      <td>-1.132710e-16</td>\n",
              "      <td>7.331380e-17</td>\n",
              "      <td>5.504428e-17</td>\n",
              "      <td>2.946696e-18</td>\n",
              "      <td>4.537912e-16</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.793608e-17</td>\n",
              "      <td>4.019294e-17</td>\n",
              "      <td>1.379054e-17</td>\n",
              "      <td>2.805255e-17</td>\n",
              "      <td>1.909459e-16</td>\n",
              "      <td>-1.155105e-17</td>\n",
              "      <td>3.500675e-17</td>\n",
              "      <td>-1.183393e-16</td>\n",
              "      <td>-1.284760e-17</td>\n",
              "      <td>1.941283e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.267496e+00</td>\n",
              "      <td>-3.377497e+00</td>\n",
              "      <td>-3.135009e+00</td>\n",
              "      <td>-2.476635e+00</td>\n",
              "      <td>-2.898725e+00</td>\n",
              "      <td>-2.301823e+00</td>\n",
              "      <td>-2.741345e+00</td>\n",
              "      <td>-1.998341e+00</td>\n",
              "      <td>-2.144420e+00</td>\n",
              "      <td>-4.759523e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>-2.331061e+00</td>\n",
              "      <td>-1.465640e+00</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>-3.309161e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.267496e+00</td>\n",
              "      <td>-1.946253e-01</td>\n",
              "      <td>-2.276916e-01</td>\n",
              "      <td>-7.694097e-01</td>\n",
              "      <td>-9.628269e-01</td>\n",
              "      <td>-6.803548e-01</td>\n",
              "      <td>-9.233868e-01</td>\n",
              "      <td>-4.262935e-01</td>\n",
              "      <td>-7.622820e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>-3.037048e-01</td>\n",
              "      <td>-1.465640e+00</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.099038e-01</td>\n",
              "      <td>-1.946253e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>8.420298e-02</td>\n",
              "      <td>5.122103e-03</td>\n",
              "      <td>1.303794e-01</td>\n",
              "      <td>-1.440754e-02</td>\n",
              "      <td>3.597300e-01</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>-8.052361e-01</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>1.017663e-01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.099038e-01</td>\n",
              "      <td>8.663319e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>9.378157e-01</td>\n",
              "      <td>9.730711e-01</td>\n",
              "      <td>9.411137e-01</td>\n",
              "      <td>8.945717e-01</td>\n",
              "      <td>1.145754e+00</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427251e-01</td>\n",
              "      <td>-2.432228e-01</td>\n",
              "      <td>1.241872e+00</td>\n",
              "      <td>-2.898989e-01</td>\n",
              "      <td>9.127086e-01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>-3.518703e-01</td>\n",
              "      <td>-5.116614e-01</td>\n",
              "      <td>-3.021914e-02</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.464702e+00</td>\n",
              "      <td>8.663319e-01</td>\n",
              "      <td>7.414143e-01</td>\n",
              "      <td>9.378157e-01</td>\n",
              "      <td>9.730711e-01</td>\n",
              "      <td>9.411137e-01</td>\n",
              "      <td>8.945717e-01</td>\n",
              "      <td>1.145754e+00</td>\n",
              "      <td>6.198564e-01</td>\n",
              "      <td>3.296665e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>4.119886e+00</td>\n",
              "      <td>4.111456e+00</td>\n",
              "      <td>1.241872e+00</td>\n",
              "      <td>3.449478e+00</td>\n",
              "      <td>1.632061e+01</td>\n",
              "      <td>6.822956e-01</td>\n",
              "      <td>2.841956e+00</td>\n",
              "      <td>1.954418e+00</td>\n",
              "      <td>3.309161e+01</td>\n",
              "      <td>3.021914e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q1            Q2            Q3            Q4            Q5  \\\n",
              "count  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05   \n",
              "mean   1.049024e-16 -4.315142e-16 -1.772732e-16  1.222584e-16 -7.637836e-17   \n",
              "std    1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00   \n",
              "min   -1.267496e+00 -3.377497e+00 -3.135009e+00 -2.476635e+00 -2.898725e+00   \n",
              "25%   -1.267496e+00 -1.946253e-01 -2.276916e-01 -7.694097e-01 -9.628269e-01   \n",
              "50%    3.099038e-01 -1.946253e-01  7.414143e-01  8.420298e-02  5.122103e-03   \n",
              "75%    3.099038e-01  8.663319e-01  7.414143e-01  9.378157e-01  9.730711e-01   \n",
              "max    3.464702e+00  8.663319e-01  7.414143e-01  9.378157e-01  9.730711e-01   \n",
              "\n",
              "                 Q6            Q7            Q8            Q9           Q10  \\\n",
              "count  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05  1.205660e+05   \n",
              "mean  -1.132710e-16  7.331380e-17  5.504428e-17  2.946696e-18  4.537912e-16   \n",
              "std    1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00  1.000004e+00   \n",
              "min   -2.301823e+00 -2.741345e+00 -1.998341e+00 -2.144420e+00 -4.759523e+00   \n",
              "25%   -6.803548e-01 -9.233868e-01 -4.262935e-01 -7.622820e-01  3.296665e-01   \n",
              "50%    1.303794e-01 -1.440754e-02  3.597300e-01  6.198564e-01  3.296665e-01   \n",
              "75%    9.411137e-01  8.945717e-01  1.145754e+00  6.198564e-01  3.296665e-01   \n",
              "max    9.411137e-01  8.945717e-01  1.145754e+00  6.198564e-01  3.296665e-01   \n",
              "\n",
              "       ...  RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto  \\\n",
              "count  ...                                       1.205660e+05            \n",
              "mean   ...                                      -6.793608e-17            \n",
              "std    ...                                       1.000004e+00            \n",
              "min    ...                                      -2.427251e-01            \n",
              "25%    ...                                      -2.427251e-01            \n",
              "50%    ...                                      -2.427251e-01            \n",
              "75%    ...                                      -2.427251e-01            \n",
              "max    ...                                       4.119886e+00            \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de Sorocaba  \\\n",
              "count                                       1.205660e+05      \n",
              "mean                                        4.019294e-17      \n",
              "std                                         1.000004e+00      \n",
              "min                                        -2.432228e-01      \n",
              "25%                                        -2.432228e-01      \n",
              "50%                                        -2.432228e-01      \n",
              "75%                                        -2.432228e-01      \n",
              "max                                         4.111456e+00      \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana de São Paulo  \\\n",
              "count                                       1.205660e+05       \n",
              "mean                                        1.379054e-17       \n",
              "std                                         1.000004e+00       \n",
              "min                                        -8.052361e-01       \n",
              "25%                                        -8.052361e-01       \n",
              "50%                                        -8.052361e-01       \n",
              "75%                                         1.241872e+00       \n",
              "max                                         1.241872e+00       \n",
              "\n",
              "       RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte  \\\n",
              "count                                       1.205660e+05                             \n",
              "mean                                        2.805255e-17                             \n",
              "std                                         1.000004e+00                             \n",
              "min                                        -2.898989e-01                             \n",
              "25%                                        -2.898989e-01                             \n",
              "50%                                        -2.898989e-01                             \n",
              "75%                                        -2.898989e-01                             \n",
              "max                                         3.449478e+00                             \n",
              "\n",
              "              idade  PERIODO_MANHÃ  PERIODO_NOITE  PERIODO_TARDE  \\\n",
              "count  1.205660e+05   1.205660e+05   1.205660e+05   1.205660e+05   \n",
              "mean   1.909459e-16  -1.155105e-17   3.500675e-17  -1.183393e-16   \n",
              "std    1.000004e+00   1.000004e+00   1.000004e+00   1.000004e+00   \n",
              "min   -2.331061e+00  -1.465640e+00  -3.518703e-01  -5.116614e-01   \n",
              "25%   -3.037048e-01  -1.465640e+00  -3.518703e-01  -5.116614e-01   \n",
              "50%    1.017663e-01   6.822956e-01  -3.518703e-01  -5.116614e-01   \n",
              "75%    9.127086e-01   6.822956e-01  -3.518703e-01  -5.116614e-01   \n",
              "max    1.632061e+01   6.822956e-01   2.841956e+00   1.954418e+00   \n",
              "\n",
              "       Tipo_PROVA_A  Tipo_PROVA_C  \n",
              "count  1.205660e+05  1.205660e+05  \n",
              "mean  -1.284760e-17  1.941283e-16  \n",
              "std    1.000004e+00  1.000004e+00  \n",
              "min   -3.021914e-02 -3.309161e+01  \n",
              "25%   -3.021914e-02  3.021914e-02  \n",
              "50%   -3.021914e-02  3.021914e-02  \n",
              "75%   -3.021914e-02  3.021914e-02  \n",
              "max    3.309161e+01  3.021914e-02  \n",
              "\n",
              "[8 rows x 85 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cie_lr.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Function to split the data into train and validation sets\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(df, target, validation_size):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    return train_test_split(X, y, test_size=validation_size, random_state=42)\n",
        "\n",
        "    \n",
        "X_train_cie, X_val_cie, y_train_cie, y_val_cie = split_data(df_cie_lr, 'porc_ACERT_CIE', 0.2)\n",
        "X_train_mat, X_val_mat, y_train_mat, y_val_mat = split_data(df_mat_lr, 'porc_ACERT_MAT', 0.2)\n",
        "X_train_lp, X_val_lp, y_train_lp, y_val_lp = split_data(df_lp_lr, 'porc_ACERT_lp', 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_cie = df_cie_lr_test.drop(columns=['porc_ACERT_CIE'])\n",
        "X_test_mat = df_mat_lr_test.drop(columns=['porc_ACERT_MAT'])\n",
        "X_test_lp = df_lp_lr_test.drop(columns=['porc_ACERT_lp'])\n",
        "y_test_cie = df_cie_lr_test['porc_ACERT_CIE']\n",
        "y_test_mat = df_mat_lr_test['porc_ACERT_MAT']\n",
        "y_test_lp = df_lp_lr_test['porc_ACERT_lp']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6 µs, sys: 4 µs, total: 10 µs\n",
            "Wall time: 14.5 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\"\"\"Function to evaluate the model using the validation set and the R2 score\"\"\"\n",
        "def evaluate_model(X_val, y_val, w, b):\n",
        "    from sklearn.metrics import r2_score\n",
        "    y_pred = np.dot(X_val, w) + b\n",
        "    error = y_pred - y_val\n",
        "    mse = (1/X_val.shape[0]) * np.sum(error**2)\n",
        "    return mse, r2_score(y_val, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "D9cpdif9JxFR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Science\n",
            "Epoch: 0, Train Loss: 1.0010108751508435, Val Loss: 0.9798645458947729, R2: 0.022047949501030617\n",
            "Epoch: 100, Train Loss: 0.5067849076124425, Val Loss: 0.5034068677858039, R2: 0.49757567956820514\n",
            "Epoch: 200, Train Loss: 0.48522448214157526, Val Loss: 0.482192058212657, R2: 0.5187490821674989\n",
            "Epoch: 300, Train Loss: 0.4814269819125148, Val Loss: 0.4785609728003654, R2: 0.522373080442939\n",
            "Epoch: 400, Train Loss: 0.480334782274382, Val Loss: 0.4775556670912004, R2: 0.5233764240007553\n",
            "Epoch: 500, Train Loss: 0.4798503540468307, Val Loss: 0.47711845448358636, R2: 0.523812783258687\n",
            "Epoch: 600, Train Loss: 0.479537151030252, Val Loss: 0.4768331182205701, R2: 0.5240975626036153\n",
            "Epoch: 700, Train Loss: 0.4792864549944948, Val Loss: 0.4765999196368881, R2: 0.5243303060313073\n",
            "Epoch: 800, Train Loss: 0.47906693289807595, Val Loss: 0.47639147377069413, R2: 0.5245383450537583\n",
            "Epoch: 900, Train Loss: 0.4788679409249277, Val Loss: 0.4761990511279383, R2: 0.5247303921268296\n",
            "Math\n",
            "Epoch: 0, Train Loss: 0.998248280873062, Val Loss: 0.9748441063488577, R2: 0.029727483532188126\n",
            "Epoch: 100, Train Loss: 0.45983605526009846, Val Loss: 0.4561068032223282, R2: 0.5460321369761174\n",
            "Epoch: 200, Train Loss: 0.44388683861155537, Val Loss: 0.44051391351887126, R2: 0.5615519028884776\n",
            "Epoch: 300, Train Loss: 0.44166861380048433, Val Loss: 0.4385471842763504, R2: 0.5635094090363053\n",
            "Epoch: 400, Train Loss: 0.4411647483205638, Val Loss: 0.4381924006717204, R2: 0.5638625288619512\n",
            "Epoch: 500, Train Loss: 0.4410088577858932, Val Loss: 0.4381266016048728, R2: 0.56392801936013\n",
            "Epoch: 600, Train Loss: 0.4409476234008252, Val Loss: 0.43812096559896235, R2: 0.5639336289356529\n",
            "Epoch: 700, Train Loss: 0.4409188145578968, Val Loss: 0.4381265042433048, R2: 0.5639281162651151\n",
            "Epoch: 800, Train Loss: 0.440903269229028, Val Loss: 0.4381318489327718, R2: 0.5639227966398899\n",
            "Epoch: 900, Train Loss: 0.44089387252776857, Val Loss: 0.43813472088771327, R2: 0.5639199381531532\n",
            "Portuguese\n",
            "Epoch: 0, Train Loss: 1.0008642768810452, Val Loss: 0.9678060960417534, R2: 0.028026665569307663\n",
            "Epoch: 100, Train Loss: 0.46646938885271033, Val Loss: 0.4627124070706311, R2: 0.5352952176863638\n",
            "Epoch: 200, Train Loss: 0.4449476894541054, Val Loss: 0.44330501289350355, R2: 0.5547861774024716\n",
            "Epoch: 300, Train Loss: 0.4411397074238675, Val Loss: 0.4402307438702204, R2: 0.557873683800415\n",
            "Epoch: 400, Train Loss: 0.4401957290744583, Val Loss: 0.4396132307527298, R2: 0.5584938558434688\n",
            "Epoch: 500, Train Loss: 0.4399124183119337, Val Loss: 0.4394900124551668, R2: 0.5586176047018765\n",
            "Epoch: 600, Train Loss: 0.43980446932157874, Val Loss: 0.4394651935232241, R2: 0.5586425305006868\n",
            "Epoch: 700, Train Loss: 0.439749038185925, Val Loss: 0.4394547571422861, R2: 0.558653011819229\n",
            "Epoch: 800, Train Loss: 0.43971177414694346, Val Loss: 0.4394427740304207, R2: 0.5586650465287067\n",
            "Epoch: 900, Train Loss: 0.43968208735021624, Val Loss: 0.43942787532888955, R2: 0.5586800093819737\n",
            "CPU times: user 4min 45s, sys: 4min 55s, total: 9min 41s\n",
            "Wall time: 57.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TODO: Linear Regression. Implement your solution. You cannot use scikit-learn, Keras/TensorFlow, or PyTorch libraries.\n",
        "\n",
        "\n",
        "def linear_regression(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    train_loss, val_loss,  r2_list = [], [], []\n",
        "    w = np.random.rand(X_train.shape[1])*0.001 - 0.0005\n",
        "    b = 0\n",
        "    m = X_train.shape[0]\n",
        "    for i in range(epochs):\n",
        "        y_pred = np.dot(X_train, w) + b\n",
        "        error = y_pred - y_train\n",
        "        mse = (1/m) * np.sum(error**2)\n",
        "        w = w - (learning_rate * (1/m) * np.dot(X_train.T, error))\n",
        "        b = b - (learning_rate * (1/m) * np.sum(error))\n",
        "        mse_val, r2 = evaluate_model(X_val, y_val, w, b)\n",
        "        train_loss.append(mse)\n",
        "        val_loss.append(mse_val)\n",
        "        r2_list.append(r2)\n",
        "        if i % 100 == 0:\n",
        "            print(\"Epoch: {}, Train Loss: {}, Val Loss: {}, R2: {}\".format(\n",
        "                i, mse, mse_val, r2))\n",
        "    return w, b, train_loss, val_loss, r2_list\n",
        "\n",
        "\n",
        "print('Science')\n",
        "w_cie, b_cie, train_loss_cie, val_loss_cie, r2_cie = linear_regression(\n",
        "   X_train_cie, y_train_cie, X_val_cie, y_val_cie, 0.01, 1000)\n",
        "print('Math')\n",
        "w_mat, b_mat,  train_loss_mat, val_loss_mat, r2_mat = linear_regression(\n",
        "   X_train_mat, y_train_mat, X_val_mat, y_val_mat, 0.01, 1000)\n",
        "print('Portuguese')\n",
        "w_lp, b_lp,  train_loss_lp, val_loss_lp, r2_lp = linear_regression(\n",
        "   X_train_lp, y_train_lp, X_val_lp, y_val_lp, 0.01, 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "e4nZrMr_C2X7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Science\n",
            "r2: 0.5277387313934802\n",
            "Math\n",
            "r2: 0.5640692321041819\n",
            "Portuguese\n",
            "r2: 0.558988332260711\n",
            "CPU times: user 13.8 s, sys: 7.98 s, total: 21.8 s\n",
            "Wall time: 2.36 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# TODO: Linear Regression. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def linear_regression_sklearn(X_train, y_train):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "model_cie = linear_regression_sklearn(X_train_cie, y_train_cie )\n",
        "model_mat = linear_regression_sklearn(X_train_mat, y_train_mat)\n",
        "model_lp = linear_regression_sklearn(X_train_lp, y_train_lp)\n",
        "print('Science')\n",
        "print(f'r2: {model_cie.score(X_val_cie, y_val_cie)}')\n",
        "print('Math')\n",
        "print(f'r2: {model_mat.score(X_val_mat, y_val_mat)}')\n",
        "print('Portuguese')\n",
        "print(f'r2: {model_lp.score(X_val_lp, y_val_lp)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_regression_cv(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    train_loss, val_loss,  r2_list = [], [], []\n",
        "    w = np.random.rand(X_train.shape[1])*0.001 - 0.0005\n",
        "    b = 0\n",
        "    m = X_train.shape[0]\n",
        "    for i in range(epochs):\n",
        "        y_pred = np.dot(X_train, w) + b\n",
        "        error = y_pred - y_train\n",
        "        mse = (1/m) * np.sum(error**2)\n",
        "        w = w - (learning_rate * (1/m) * np.dot(X_train.T, error))\n",
        "        b = b - (learning_rate * (1/m) * np.sum(error))\n",
        "        mse_val, r2 = evaluate_model(X_val, y_val, w, b)\n",
        "        train_loss.append(mse)\n",
        "        val_loss.append(mse_val)\n",
        "        r2_list.append(r2)\n",
        "    return w, b, train_loss, val_loss, r2_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "porc_ACERT_CIE\n",
            "porc_ACERT_MAT\n",
            "porc_ACERT_lp\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m final_r2_cie \u001b[39m=\u001b[39m k_fold_lin_reg(df_cie_lr_cv, \u001b[39m'\u001b[39m\u001b[39mporc_ACERT_CIE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m final_r2_mat \u001b[39m=\u001b[39m k_fold_lin_reg(df_mat_lr_cv, \u001b[39m'\u001b[39m\u001b[39mporc_ACERT_MAT\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m final_r2_lp \u001b[39m=\u001b[39m k_fold_lin_reg(df_lp_lr_cv, \u001b[39m'\u001b[39;49m\u001b[39mporc_ACERT_lp\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mScience\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m media_cie \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 60\u001b[0m in \u001b[0;36mk_fold_lin_reg\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     y_train \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[i[\u001b[39m0\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     y_val \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[i[\u001b[39m1\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     w, b, train_loss, val_loss, r2 \u001b[39m=\u001b[39m linear_regression_cv(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         X_train, y_train, X_val, y_val, \u001b[39m0.01\u001b[39;49m, \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     final_r2\u001b[39m.\u001b[39mappend(r2[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m final_r2\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 60\u001b[0m in \u001b[0;36mlinear_regression_cv\u001b[0;34m(X_train, y_train, X_val, y_val, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m (learning_rate \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mm) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(X_train\u001b[39m.\u001b[39mT, error))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m-\u001b[39m (learning_rate \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mm) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(error))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mse_val, r2 \u001b[39m=\u001b[39m evaluate_model(X_val, y_val, w, b)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_loss\u001b[39m.\u001b[39mappend(mse)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y113sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m val_loss\u001b[39m.\u001b[39mappend(mse_val)\n",
            "File \u001b[0;32m<timed exec>:4\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(X_val, y_val, w, b)\u001b[0m\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def k_fold_lin_reg(df, target):\n",
        "\n",
        "    kf = KFold(n_splits=10)\n",
        "    y = df[target]\n",
        "    X = df.drop(columns=[target])\n",
        "    final_r2 = []\n",
        "    print(f\"{target}\")\n",
        "\n",
        "    for i in kf.split(X):\n",
        "\n",
        "        X_train = X.iloc[i[0]]\n",
        "        X_val = X.iloc[i[1]]\n",
        "        y_train = y.iloc[i[0]]\n",
        "        y_val = y.iloc[i[1]]\n",
        "\n",
        "        w, b, train_loss, val_loss, r2 = linear_regression_cv(\n",
        "            X_train, y_train, X_val, y_val, 0.01, 1000)\n",
        "        final_r2.append(r2[-1])\n",
        "\n",
        "    return final_r2\n",
        "\n",
        "\n",
        "df_cie_lr_cv = df_cie_lr\n",
        "df_mat_lr_cv = df_mat_lr\n",
        "df_lp_lr_cv = df_lp_lr\n",
        "\n",
        "final_r2_cie = k_fold_lin_reg(df_cie_lr_cv, 'porc_ACERT_CIE')\n",
        "final_r2_mat = k_fold_lin_reg(df_mat_lr_cv, 'porc_ACERT_MAT')\n",
        "final_r2_lp = k_fold_lin_reg(df_lp_lr_cv, 'porc_ACERT_lp')\n",
        "\n",
        "print('Science')\n",
        "media_cie = 0\n",
        "for i in final_r2_cie:\n",
        "    media_cie = media_cie + i\n",
        "print(f\"media cie: {media_cie/10}\")\n",
        "print('Math')\n",
        "media_mat = 0\n",
        "for i in final_r2_mat:\n",
        "    media_mat = media_mat + i\n",
        "print(f\"media mat: {media_mat/10}\")\n",
        "print('Portuguese')\n",
        "media_lp = 0\n",
        "for i in final_r2_lp:\n",
        "    media_lp = media_lp + i\n",
        "print(f\"media lp: {media_lp/10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBNZQNImKQeo"
      },
      "source": [
        "\n",
        "> What are the conclusions? (1-2 paragraphs)\n",
        "The most obvious conclusion is about time, when the scikit learn library was used to train and validate the models, the total time was 1 s, and when we used our function it took 30 seconds to train. It happened because the library is better optimized than our code, using multi thread programming and many other things.\n",
        "In terms of results, both produced the same R^2 score for all the models, showing that our solution may be as good as the one from library but much slower\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADxPBRhuK_Vq"
      },
      "source": [
        "2. (1 point) Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions with Normal Equation. What are the conclusions?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "RSZ1pLItNVbU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate:  0.1\n",
            "0.5194445513799242\n",
            "0.5560231276129228\n",
            "0.5502339172451928\n",
            "Learning rate:  0.01\n",
            "0.5187275194851213\n",
            "0.5585106618683389\n",
            "0.5523362395119682\n",
            "Learning rate:  0.001\n",
            "0.521164115270278\n",
            "0.558756365343219\n",
            "0.5541318560624998\n"
          ]
        }
      ],
      "source": [
        "# TODO: Gradient Descent (GD) with 3 different learning rates. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "def linear_regression_sklearn_sgd(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    model = SGDRegressor(alpha=learning_rate, max_iter=epochs)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "lrs = [0.1, 0.01, 0.001]\n",
        "for lr in lrs:\n",
        "    print(\"Learning rate: \", lr)\n",
        "    model_cie_sgd = linear_regression_sklearn_sgd(X_train_cie, y_train_cie, X_val_cie, y_val_cie, lr, 1000)\n",
        "    model_mat_sgd = linear_regression_sklearn_sgd(X_train_mat, y_train_mat, X_val_mat, y_val_mat, lr, 1000)\n",
        "    model_lp_sgd = linear_regression_sklearn_sgd(X_train_lp, y_train_lp, X_val_lp, y_val_lp, lr, 1000)\n",
        "    print(model_cie_sgd.score(X_val_cie, y_val_cie))\n",
        "    print(model_mat_sgd.score(X_val_mat, y_val_mat))\n",
        "    print(model_lp_sgd.score(X_val_lp, y_val_lp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPl7jKgJPW6"
      },
      "source": [
        "\n",
        "3. (0.75 point) Sometimes, we need some more complex function to make good prediction. Devise and evaluate a Polynomial Linear Regression model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjGbg41PMHR9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 66\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_cie \u001b[39m=\u001b[39m polynomial_regression(X_train_cie, y_train_cie, X_val_cie, y_val_cie, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model_mat \u001b[39m=\u001b[39m polynomial_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat, \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model_lp \u001b[39m=\u001b[39m polynomial_regression(X_train_lp, y_train_lp, X_val_lp, y_val_lp, \u001b[39m2\u001b[39m)\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 66\u001b[0m in \u001b[0;36mpolynomial_regression\u001b[0;34m(X_train, y_train, X_val, y_val, degree)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpolynomial_regression\u001b[39m(X_train, y_train, X_val, y_val, degree):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     model \u001b[39m=\u001b[39m make_pipeline(PolynomialFeatures(degree), LinearRegression())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y122sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:669\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 669\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preprocess_data(\n\u001b[1;32m    670\u001b[0m     X,\n\u001b[1;32m    671\u001b[0m     y,\n\u001b[1;32m    672\u001b[0m     fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m    673\u001b[0m     normalize\u001b[39m=\u001b[39;49m_normalize,\n\u001b[1;32m    674\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_X,\n\u001b[1;32m    675\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    676\u001b[0m     return_mean\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m     \u001b[39m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n\u001b[1;32m    681\u001b[0m     X, y \u001b[39m=\u001b[39m _rescale_data(X, y, sample_weight)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:247\u001b[0m, in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean, check_input)\u001b[0m\n\u001b[1;32m    244\u001b[0m     sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(sample_weight)\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 247\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, copy\u001b[39m=\u001b[39;49mcopy, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES)\n\u001b[1;32m    248\u001b[0m \u001b[39melif\u001b[39;00m copy:\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:821\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    815\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[0;32m--> 821\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(array, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n\u001b[1;32m    823\u001b[0m \u001b[39mreturn\u001b[39;00m array\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: Complex model. You can use scikit-learn libraries.\n",
        "\"\"\"Multi polynomial regression\"\"\"\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "def polynomial_regression(X_train, y_train, X_val, y_val, degree):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "model_cie = polynomial_regression(X_train_cie, y_train_cie, X_val_cie, y_val_cie, 2)\n",
        "model_mat = polynomial_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat, 2)\n",
        "model_lp = polynomial_regression(X_train_lp, y_train_lp, X_val_lp, y_val_lp, 2)\n",
        "print(model_cie.score(X_val_cie, y_val_cie))\n",
        "print(model_mat.score(X_val_mat, y_val_mat))\n",
        "print(model_lp.score(X_val_lp, y_val_lp))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBLKtosaLaCw"
      },
      "source": [
        "*texto em itálico*\n",
        " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldSh1vtWK5Zk"
      },
      "source": [
        "4. (0.5) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mg7aNkl_LG4P"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt20lEQVR4nO3deZxcZZ3v8e+vq6u6u3pLbyQhe0IEEpYAYZvgAOogBAdwcDAMKDoqgyMyLsMY544o3MuMOlyXOKgXHRBxBBGXQYkiagCvLJdEtqyQhIR0IPvWSaf33/2jTneqO9Xd1d11+lR3f94v+1VneeqcX1VR+OV5njrH3F0AAAAYXgVRFwAAADAWEcIAAAAiQAgDAACIACEMAAAgAoQwAACACBDCAAAAIkAIAzAmmNkqM7sg6joAoBMhDMCIY2bnmdlTZrbfzPaY2R/N7My+nuPuc9398WEqEQD6VRh1AQAwEGZWIemXkj4q6UFJCUlvldQcZV0AMFD0hAEYad4iSe5+v7u3u/thd/+Nu78kSWb2ETNbY2YNZrbazE4Ptm8ys3cEywVmttjMNpjZbjN70Myqg33TzczN7Doze93MdpnZ/+g8uZnFzOyfg+c2mNkKM5sS7DvBzB4LeufWmdlVw/3mABg5CGEARppXJLWb2b1mdomZVXXuMLO/lvQFSe+XVCHpMkm7Mxzj45KukHS+pGMl7ZV0Z48250k6XtLbJd1iZicG2z8l6WpJC4Nz/K2kRjMrlfSYpB9KOkbSIknfNLM5Q3y9AEYpQhiAEcXdDygVkFzSdyTtNLOHzWy8pA9L+rK7P+cp6919c4bD3CDpf7h7vbs3KxXc3mNm6VM0bg162V6U9KKkU4PtH5b0L+6+LjjHi+6+W9K7JG1y93vcvc3dn5f0E0l/nft3AcBowJwwACOOu6+R9AEpNQQo6QeSviZpiqQNWRximqSfmVlH2rZ2SePT1relLTdKKguWezvHNElnm9m+tG2Fku7Loh4AYxA9YQBGNHdfK+l7kk6StEXSrCyetkXSJe4+Lu2v2N23ZvncTOfYIumJHscsc/ePZvlSAIwxhDAAI0ow+f3TZjY5WJ+i1BytZyR9V9I/mtkZlnKcmU3LcJhvS7q9c5+Z1ZnZ5VmW8F1J/9PMZgfnOMXMapT6xeZbzOx9ZhYP/s5Mm0sGAN0QwgCMNA2Szpb0rJkdUip8rZT0aXf/saTblZoc3yDp55KqMxzj65IelvQbM2sIjnF2luf/ilKXxviNpAOS/lNSibs3SLpIqQn5byg1nPklSUUDf4kAxgJz96hrAAAAGHPoCQMAAIgAIQwAACAChDAAAIAIEMIAAAAiQAgDAACIwIi7Yn5tba1Pnz496jIAAAD6tWLFil3uXpdp34gLYdOnT9fy5cujLgMAAKBfZpbp/rWSGI4EAACIBCEMAAAgAoQwAACACIy4OWEAACC3WltbVV9fr6ampqhLGbGKi4s1efJkxePxrJ9DCAMAYIyrr69XeXm5pk+fLjOLupwRx921e/du1dfXa8aMGVk/j+FIAADGuKamJtXU1BDABsnMVFNTM+CeREIYAAAggA3RYN4/QhgAAIjUvn379M1vfnNQz124cKH27duXdfsvfOELuuOOOwZ1rlwjhAEAgEj1FcLa2tr6fO7SpUs1bty4EKoKX2ghzMzuNrMdZrayl/1mZkvMbL2ZvWRmp4dVCwAAyF+LFy/Whg0bNG/ePN188816/PHH9da3vlWXXXaZ5syZI0m64oordMYZZ2ju3Lm66667up47ffp07dq1S5s2bdKJJ56oj3zkI5o7d64uuugiHT58uM/zvvDCCzrnnHN0yimn6N3vfrf27t0rSVqyZInmzJmjU045RYsWLZIkPfHEE5o3b57mzZun0047TQ0NDUN+3WH+OvJ7kv5D0vd72X+JpNnB39mSvhU8AgCAiNz6i1Va/caBnB5zzrEV+vxfzu11/xe/+EWtXLlSL7zwgiTp8ccf15/+9CetXLmy69eGd999t6qrq3X48GGdeeaZuvLKK1VTU9PtOK+++qruv/9+fec739FVV12ln/zkJ7r22mt7Pe/73/9+feMb39D555+vW265Rbfeequ+9rWv6Ytf/KJee+01FRUVdQ113nHHHbrzzju1YMECHTx4UMXFxUN7UxRiT5i7PylpTx9NLpf0fU95RtI4M5sYVj3Z2tnQrGVrd+hgc9/dnwAAIDxnnXVWt8s9LFmyRKeeeqrOOeccbdmyRa+++upRz5kxY4bmzZsnSTrjjDO0adOmXo+/f/9+7du3T+eff74k6brrrtOTTz4pSTrllFN0zTXX6Ac/+IEKC1P9VQsWLNCnPvUpLVmyRPv27evaPhRRXidskqQtaev1wbY3ezY0s+slXS9JU6dODbWoP72+V3933wo9ctN5mntsZajnAgAg3/TVYzWcSktLu5Yff/xx/fa3v9XTTz+tZDKpCy64IOPlIIqKirqWY7FYv8ORvXnkkUf05JNP6he/+IVuv/12vfzyy1q8eLEuvfRSLV26VAsWLNCjjz6qE044YVDH7zQiJua7+13uPt/d59fV1YV6rpJ4TJJ0uKU91PMAAICU8vLyPudY7d+/X1VVVUomk1q7dq2eeeaZIZ+zsrJSVVVV+sMf/iBJuu+++3T++eero6NDW7Zs0YUXXqgvfelL2r9/vw4ePKgNGzbo5JNP1mc+8xmdeeaZWrt27ZBriLInbKukKWnrk4NtkUomghDWSggDAGA41NTUaMGCBTrppJN0ySWX6NJLL+22/+KLL9a3v/1tnXjiiTr++ON1zjnn5OS89957r2644QY1NjZq5syZuueee9Te3q5rr71W+/fvl7vrpptu0rhx4/S5z31Oy5YtU0FBgebOnatLLrlkyOc3d8/By+jl4GbTJf3S3U/KsO9SSTdKWqjUhPwl7n5Wf8ecP3++L1++PNeldlm5db/e9Y3/q7ved4YumjshtPMAAJAv1qxZoxNPPDHqMka8TO+jma1w9/mZ2ofWE2Zm90u6QFKtmdVL+rykuCS5+7clLVUqgK2X1Cjpg2HVMhD0hAEAgOEQWghz96v72e+SPhbW+QerJMGcMAAAEL4RMTF/OHVNzKcnDAAAhIgQ1kNnT1gjPWEAgDEkzDniY8Fg3j9CWA+JWIEKTGqiJwwAMEYUFxdr9+7dBLFBcnft3r17wFfRj/ISFXnJzFQSj9ETBgAYMyZPnqz6+nrt3Lkz6lJGrOLiYk2ePHlAzyGEZVCSKGROGABgzIjH491uEYThwXBkBiWJAjXREwYAAEJECMuA4UgAABA2QlgGDEcCAICwEcIyKIkXcLFWAAAQKkJYBkl6wgAAQMgIYRmUxGOEMAAAECpCWAbF8RjDkQAAIFSEsAySCXrCAABAuAhhGZQkYmpsaYu6DAAAMIoRwjIojsfU1Nqhjg7uoQUAAMJBCMsgmYhJkprbOiKuBAAAjFaEsAxK4qkQxpAkAAAICyEsg84QxuR8AAAQFkJYBiXBcCSXqQAAAGEhhGVATxgAAAgbISyDJD1hAAAgZISwDIqDENZITxgAAAgJISyDzuHIJnrCAABASAhhGXQNR9ITBgAAQkIIy+DIdcIIYQAAIByEsAw654Q10RMGAABCQgjLgJ4wAAAQNkJYBvFYgeIxY04YAAAIDSGsF8XxGNcJAwAAoSGE9SKZIIQBAIDwEMJ6URKPMRwJAABCQwjrRUmikIn5AAAgNISwXiQTMR1ubYu6DAAAMEoRwnqRTMR0qJmeMAAAEA5CWC/Kigp1qJmeMAAAEA5CWC+SzAkDAAAhIoT1orQopkMt9IQBAIBwEMJ6UcpwJAAACBEhrBeliZha210tbR1RlwIAAEYhQlgvkolCSVIjQ5IAACAEhLBelBWlQthBhiQBAEAICGG9SBbFJIlfSAIAgFAQwnpRGgxHMjkfAACEgRDWi9KizhBGTxgAAMg9QlgvkonUcCTXCgMAAGEghPWic2I+v44EAABhIIT1onNi/kGGIwEAQAgIYb3onJjfyMR8AAAQglBDmJldbGbrzGy9mS3OsH+amf3OzF4ys8fNbHKY9QxESTwmM+kQl6gAAAAhCC2EmVlM0p2SLpE0R9LVZjanR7M7JH3f3U+RdJukfwurnoEqKDAl4zEuUQEAAEIRZk/YWZLWu/tGd2+R9ICky3u0mSPp98Hysgz7I5UsKmRiPgAACEWYIWySpC1p6/XBtnQvSvqrYPndksrNrKbngczsejNbbmbLd+7cGUqxmZQVFXKdMAAAEIqoJ+b/o6Tzzex5SedL2irpqNTj7ne5+3x3n19XVzdsxSUTDEcCAIBwFIZ47K2SpqStTw62dXH3NxT0hJlZmaQr3X1fiDUNSGmikIu1AgCAUITZE/acpNlmNsPMEpIWSXo4vYGZ1ZpZZw2flXR3iPUMWGlRjBt4AwCAUIQWwty9TdKNkh6VtEbSg+6+ysxuM7PLgmYXSFpnZq9IGi/p9rDqGYxkUaEOMhwJAABCEOZwpNx9qaSlPbbdkrb8kKSHwqxhKMoShWpkYj4AAAhB1BPz81qyKMacMAAAEApCWB9KE4U61Nwmd4+6FAAAMMoQwvpQWlSoDpea2zqiLgUAAIwyhLA+lBbFJIlrhQEAgJwjhPUhmUj9boGr5gMAgFwjhPWhrLMnjMn5AAAgxwhhfTjSE0YIAwAAuUUI60NZcSqENRDCAABAjhHC+lARhLCDTYQwAACQW4SwPpQVxSVJDYQwAACQY4SwPpR39oQ1t0ZcCQAAGG0IYX1IJmIqMHrCAABA7hHC+mBmKisqJIQBAICcI4T1o7w4TggDAAA5RwjrR3lxIXPCAABAzhHC+sFwJAAACAMhrB/lxYQwAACQe4SwfpQVx3WQK+YDAIAcI4T1I9UTxpwwAACQW4SwfpQzJwwAAISAENaP8uJCNbd1qKWtI+pSAADAKEII60dZUeeti+gNAwAAuUMI60d5cedNvJkXBgAAcocQ1o+y4CbezAsDAAC5RAjrRzkhDAAAhIAQ1o+KYDiSOWEAACCXCGH96JyYz5wwAACQS4SwfnQOR9ITBgAAcokQ1g8m5gMAgDAQwvpRVBhTorCAEAYAAHKKEJaF1K2LmBMGAAByhxCWhdRNvOkJAwAAuUMIy0JZcSET8wEAQE4RwrJQXhRnOBIAAOQUISwLFSWF2n+YEAYAAHKHEJaFypI4IQwAAOQUISwLhDAAAJBrhLAsVJbE1dTaoea29qhLAQAAowQhLAuVJambeNMbBgAAcoUQloWKIIQdIIQBAIAcIYRlgZ4wAACQa4SwLBDCAABArhHCskAIAwAAuUYIy0JXCGskhAEAgNwghGWhoqsnjPtHAgCA3CCEZSEeK1BpIsZwJAAAyBlCWJa4aj4AAMglQliWKghhAAAgh0INYWZ2sZmtM7P1ZrY4w/6pZrbMzJ43s5fMbGGY9QxFZUmci7UCAICcCS2EmVlM0p2SLpE0R9LVZjanR7N/kfSgu58maZGkb4ZVz1AxHAkAAHIpzJ6wsyStd/eN7t4i6QFJl/do45IqguVKSW+EWM+QEMIAAEAuhRnCJknakrZeH2xL9wVJ15pZvaSlkj6e6UBmdr2ZLTez5Tt37gyj1n4RwgAAQC5FPTH/aknfc/fJkhZKus/MjqrJ3e9y9/nuPr+urm7Yi5RSIexwa7ta2joiOT8AABhdwgxhWyVNSVufHGxL9yFJD0qSuz8tqVhSbYg1DVplklsXAQCA3AkzhD0nabaZzTCzhFIT7x/u0eZ1SW+XJDM7UakQFs14Yz+4fyQAAMil0EKYu7dJulHSo5LWKPUryFVmdpuZXRY0+7Skj5jZi5Lul/QBd/ewahqKCkIYAADIocIwD+7uS5WacJ++7Za05dWSFoRZQ66M6wphLRFXAgAARoOoJ+aPGNWlCUnS3kP0hAEAgKEjhGVpXDIIYY30hAEAgKEjhGWporhQsQLTnkOEMAAAMHSEsCyZmaqSCe1tZDgSAAAMHSFsAKpL49pLTxgAAMgBQtgAVCUT2sOcMAAAkAOEsAGoSiboCQMAADlBCBuAqtIEv44EAAA5QQgbgOrSuPY2tipPL+oPAABGEELYAFQlE2rvcB1oaou6FAAAMMIRwgagqvOCrcwLAwAAQ0QIG4DOWxfxC0kAADBUhLABqCqlJwwAAOQGIWwAqrvuH8lV8wEAwNAQwgagqjQuiZ4wAAAwdISwASgrKlRhgTEnDAAADBkhbADMLHXBVnrCAADAEBHCBqg6mdAeQhgAABgiQtgAVZXGtY+J+QAAYIgIYQNUXZrQrkPNUZcBAABGuKxCmJmVmllBsPwWM7vMzOLhlpafasuKtKuBEAYAAIYm256wJyUVm9kkSb+R9D5J3wurqHxWW1akA01tam5rj7oUAAAwgmUbwszdGyX9laRvuvtfS5obXln5q7asSJKYnA8AAIYk6xBmZudKukbSI8G2WDgl5bfastRV83c1EMIAAMDgZRvCPiHps5J+5u6rzGympGWhVZXHastTPWG7DjIvDAAADF5hNo3c/QlJT0hSMEF/l7vfFGZh+aouGI7cSQgDAABDkO2vI39oZhVmVipppaTVZnZzuKXlp5rO4UhCGAAAGIJshyPnuPsBSVdI+pWkGUr9QnLMSSYKlUzEmBMGAACGJNsQFg+uC3aFpIfdvVWSh1ZVnqstK6InDAAADEm2Iez/SNokqVTSk2Y2TdKBsIrKd7VlCUIYAAAYkqxCmLsvcfdJ7r7QUzZLujDk2vJWbVmRdh9kOBIAAAxethPzK83sK2a2PPj730r1io1JteUMRwIAgKHJdjjybkkNkq4K/g5IuiesovJdbVmR9jS2qK29I+pSAADACJXVdcIkzXL3K9PWbzWzF0KoZ0SoK0vIXdrT2KJjyoujLgcAAIxA2faEHTaz8zpXzGyBpMPhlJT/Ou8fyWUqAADAYGXbE3aDpO+bWWWwvlfSdeGUlP+4dREAABiqbG9b9KKkU82sIlg/YGafkPRSiLXlrc5bF+1oIIQBAIDByXY4UlIqfAVXzpekT4VQz4gwviI1D2xHQ1PElQAAgJFqQCGsB8tZFSNMSSKmiuJCbd9PCAMAAIMzlBA2Zm9bJKV6w7YfYDgSAAAMTp9zwsysQZnDlkkqCaWiEWJ8RbG2HaAnDAAADE6fIczdy4erkJFmfEWxNm7YFXUZAABghBrKcOSYNr6iSDsamtXRMaZHZQEAwCARwgZpQmWx2jpcuw9xwVYAADBwhLBB6rxd0XbmhQEAgEEghA3S+IrUBVsJYQAAYDAIYYM0obKzJ4zLVAAAgIEjhA1SbVmRzMRlKgAAwKCEGsLM7GIzW2dm681scYb9XzWzF4K/V8xsX5j15FI8VqDasiLtIIQBAIBByOoG3oNhZjFJd0r6C0n1kp4zs4fdfXVnG3f/ZFr7j0s6Lax6wjC+ooieMAAAMChh9oSdJWm9u2909xZJD0i6vI/2V0u6P8R6cm58ebG2cf9IAAAwCGGGsEmStqSt1wfbjmJm0yTNkPT7XvZfb2bLzWz5zp07c17oYE0cx62LAADA4OTLxPxFkh5y9/ZMO939Lnef7+7z6+rqhrm03h07rkT7Glt1qLkt6lIAAMAIE2YI2yppStr65GBbJos0woYiJWnSuNQ9zN/YdzjiSgAAwEgTZgh7TtJsM5thZgmlgtbDPRuZ2QmSqiQ9HWItoegMYVsJYQAAYIBCC2Hu3ibpRkmPSloj6UF3X2Vmt5nZZWlNF0l6wN1H3J2wjyWEAQCAQQrtEhWS5O5LJS3tse2WHutfCLOGMI2vKFaswBiOBAAAA5YvE/NHpFiBaUJFsd7Yxy8kAQDAwBDChmhSVYm27qUnDAAADAwhbIgmjSthThgAABgwQtgQHRtcsLWtvSPqUgAAwAhCCBuiSeOSau9w7WhojroUAAAwghDChujYccWSuGArAAAYGELYEE2u4lphAABg4AhhQzRpXFKS9PruxogrAQAAIwkhbIhKEjEdU16kzXsIYQAAIHuEsByYVpPU64QwAAAwAISwHJhaXcpwJAAAGBBCWA5MrU5q24EmNbW2R10KAAAYIQhhOTCtJjU5v34vvWEAACA7hLAcmBqEsM0MSQIAgCwRwnJgajUhDAAADAwhLAdqShMqTcT4hSQAAMgaISwHzExTa0oJYQAAIGuEsByZVp3U5t2Hoi4DAACMEISwHJlWm9SWPYfV1t4RdSkAAGAEIITlyKy6MrW0d6h+LzfyBgAA/SOE5cisujJJ0sZdByOuBAAAjASEsByZVVcqSdqwg3lhAACgf4SwHBmXTKimNKENO+kJAwAA/SOE5dCsujJt3ElPGAAA6B8hLIdm1pXSEwYAALJCCMuhWXVl2n2oRfsaW6IuBQAA5DlCWA7NOiaYnM+QJAAA6AchLIdm1qYuU8GQJAAA6A8hLIemVCdVVFigV7Y1RF0KAADIc4SwHIoVmGaPL9O67YQwAADQN0JYjh0/vkJr6QkDAAD9IITl2AkTyrWzoVl7DvELSQAA0DtCWI4dP6FckrR224GIKwEAAPmMEJZjJwQhbB1DkgAAoA+EsByrKy9SVTJOCAMAAH0ihOWYmen4CeVMzgcAAH0ihIXghAkVWretQe0dHnUpAAAgTxHCQjD32Aodbm3Xa7u4cj4AAMiMEBaCkydXSpJe3ro/4koAAEC+IoSF4Li6MhXHC/RyPZepAAAAmRHCQlAYK9CciRV6eeu+qEsBAAB5ihAWkpMnVWrVGweYnA8AADIihIXkpEmVamxhcj4AAMiMEBYSJucDAIC+EMJCclxdmUriMb24hRAGAACORggLSWGsQKdOqdSKzXujLgUAAOQhQliIzphWpdVvHlBjS1vUpQAAgDwTaggzs4vNbJ2ZrTezxb20ucrMVpvZKjP7YZj1DLczplWpvcP1Uj1DkgAAoLvQQpiZxSTdKekSSXMkXW1mc3q0mS3ps5IWuPtcSZ8Iq54onDalSpIYkgQAAEcJsyfsLEnr3X2ju7dIekDS5T3afETSne6+V5LcfUeI9Qy7qtKEZtaV6vnXCWEAAKC7MEPYJElb0tbrg23p3iLpLWb2RzN7xswuDrGeSJwxtUorNu+VOxdtBQAAR0Q9Mb9Q0mxJF0i6WtJ3zGxcz0Zmdr2ZLTez5Tt37hzeCofozOnV2tvYqle2c9FWAABwRJghbKukKWnrk4Nt6eolPezure7+mqRXlApl3bj7Xe4+393n19XVhVZwGM6dVSNJenrDrogrAQAA+STMEPacpNlmNsPMEpIWSXq4R5ufK9ULJjOrVWp4cmOINQ27KdVJTa4q0dMbd0ddCgAAyCOhhTB3b5N0o6RHJa2R9KC7rzKz28zssqDZo5J2m9lqScsk3ezuoy6tnDuzRs++tkcd3MwbAAAECsM8uLsvlbS0x7Zb0pZd0qeCv1Hr3Fk1+vGKeq3d1qA5x1ZEXQ4AAMgDUU/MHxM654U9xbwwAAAQIIQNg4mVJZpVV6onXhlZv+wEAADhIYQNk7edcIye3biH+0gCAABJhLBhc+Hxx6ilvUN/XD/qfncAAAAGgRA2TOZPr1ZZUaGWrRtVd2YCAACDRAgbJonCAp13XK2Wrd3BLYwAAAAhbDhdeEKd3tzfpHXbG6IuBQAARIwQNowuOP4YSdLv1jAkCQDAWEcIG0bjK4p16pRx+vXKbVGXAgAAIkYIG2Z/ecpEvbx1vzbtOhR1KQAAIEKEsGG28OSJkqRHXn4z4koAAECUCGHD7NhxJTpjWpV++RIhDACAsYwQFoFLT56oNW8e0IadB6MuBQAARIQQFoGFJ0+UmfSLF9+IuhQAABARQlgEJlQW69yZNXpoRb06OrhwKwAAYxEhLCKLzpqq+r2H9dQG7iUJAMBYRAiLyEVzxmtcMq77n3s96lIAAEAECGERKY7H9O7TJuk3q7Zpz6GWqMsBAADDjBAWoUVnTlVru+unf6qPuhQAADDMCGEROn5CueZPq9K9T29SW3tH1OUAAIBhRAiL2IffOlNb9hzWo6u2R10KAAAYRoSwiP3FnPGaXpPUXX/YKHcuVwEAwFhBCItYrMD0ofNm6MUt+7R8896oywEAAMOEEJYH3nPGFFUl4/rmsvVRlwIAAIYJISwPlCRi+sifz9SydTu1gt4wAADGBEJYnvjAn01XbVlCdzy6LupSAADAMCCE5YlkolB/f8Fxenrjbj21flfU5QAAgJARwvLI35w9VRMri/Wvv1qjdm7sDQDAqEYIyyPF8ZgWX3KCVm49oB89tyXqcgAAQIgIYXnmslOP1VkzqvXvj67VvkbuKQkAwGhFCMszZqZbL5ur/Ydb9WUm6QMAMGoRwvLQiRMr9MEFM/TDZ1/XH5mkDwDAqEQIy1M3v/N4zawt1T899JIamlqjLgcAAOQYISxPFcdjuuOqU/Xm/sO67Reroy4HAADkGCEsj50+tUp/f8Fx+vGKej20oj7qcgAAQA4RwvLcJ94xW+fOrNG//Pxlrd12IOpyAABAjhDC8lxhrEBfv3qeKorjuv77K7T7YHPUJQEAgBwghI0Ax5QX69vvO0PbDzTp+vtWqKm1PeqSAADAEBHCRojTp1bpq++dpxWb9+qTP3pBbe0dUZcEAACGgBA2giw8eaI+9645+tXKbfrkgy8SxAAAGMEKoy4AA/Oh82aotb1DX/zVWhWY9JWr5ilWYFGXBQAABogQNgLdcP4stXe4/v3RdTrc0q6vLzpNJYlY1GUBAIABYDhyhPrYhcfp8385R4+t2a6/+e4z2nOIm30DADCSEMJGsA8umKFvXXO6Vr9xQFfc+Uet3Lo/6pIAAECWCGEj3MUnTdT915+jlrYO/dW3ntKPnntd7h51WQAAoB+EsFHg9KlVeuSm83T2jGp95icv68YfPq9dXNQVAIC8RggbJWrKivS9D56lm995vB5bvV0XffVJ/eLFN+gVAwAgTxHCRpFYgeljFx6nX950nqZUJ/Xx+5/Xdfc8p1e2N0RdGgAA6CHUEGZmF5vZOjNbb2aLM+z/gJntNLMXgr8Ph1nPWPGW8eX6yQ3n6nPvmqMXXt+rS77+B33u5ysZogQAII9YWMNVZhaT9Iqkv5BUL+k5SVe7++q0Nh+QNN/db8z2uPPnz/fly5fnuNrRa8+hFn3tt6/ov559XfGY6Zqzp+nv/nymjqkojro0AABGPTNb4e7zM+0LsyfsLEnr3X2ju7dIekDS5SGeDxlUlyZ02+Un6Tef/HMtPHmivvfUJp335WX67E9f0uo3DkRdHgAAY1aYIWySpC1p6/XBtp6uNLOXzOwhM5sSYj1j2qy6Mn3lqnn6/afP15WnT9LPnt+qhUv+oKu+/bQefvENNbW2R10iAABjSpjDke+RdLG7fzhYf5+ks9OHHs2sRtJBd282s7+T9F53f1uGY10v6XpJmjp16hmbN28OpeaxZF9ji368vF73PbNZr+9pVHlRod550gRdMW+Szp1Vw/0oAQDIgb6GI8MMYedK+oK7vzNY/6wkufu/9dI+JmmPu1f2dVzmhOVWR4frqQ279d8vbNWvV25TQ3ObasuK9I4Tj9HbTjhG582uVTLBLUYBABiMqEJYoVIT898uaatSE/P/xt1XpbWZ6O5vBsvvlvQZdz+nr+MSwsLT1Nqu36/doUdeelNPvrJTDc1tShQW6NyZNVpwXI3OmVmjORMrVBjjyiYAAGSjrxAWWheHu7eZ2Y2SHpUUk3S3u68ys9skLXf3hyXdZGaXSWqTtEfSB8KqB/0rjse08OSJWnjyRLW0dei5TXv0uzU79Pi6HfrXpTslSeVFhTpzRrXmT6/SqZPH6eTJlaoojkdcOQAAI09oPWFhoScsGjsONOmZ1/bomY279cyG3dq461DXvpm1pTplcqVOmlSp2ePL9ZbxZZpQUSwz5pUBAMa2SIYjw0IIyw97D7Xo5a379VL9Pr1Yn3rcfuDIxWDLiws1+5gyzT6mXMcdU6apNUlNq0lqSlVSpUXMMQMAjA2EMAyL3Qeb9cr2g1q/o0GvbD+oV7Y36NUdB7XnUEu3drVlCU2pTmpqdVLHjivRhIpija8o0viKYk2oLFZdWRHzzgAAo0Ikc8Iw9tSUFencsiKdO6um2/a9h1q0ZW+jXt+T+tsSPK7YvFdLX35Tre3d/0PATKotK9L4iiLVlBapujShqmRCNWWpx+rSuKpLi1RdGldVMqGKkrjihDYAwAhDCEPoqkoTqipN6JTJ447a19Hh2tPYom37m7SjoUnb9jdr24EmbQ/W9xxq0cZdB7XnYIsOtfR+QdnieIHKi+MqLy5MPRYVBsuF3baXJmIqScRUEj/6MZko7FqPx4w5bQCAUBHCEKmCAlNtWZFqy4ok9XmJODW1tmtfY6t2H2rW3kOdjy1qaGpTQ3ObGppadaCpLbXe1KptB5rU0NSqhqY2NfYR4DKJFZiS8ZiKg4CWKCxQIlaQeiwsUFGwHk/b1tmmKG05UZjWJlagWIGpMGapx4ICFRaYYjFTvKD7vvT1wqBtrGv56PVYAaERAEYaQhhGjOJ4TBMqY5pQOfCbj7e1d+hgcyqMHW5t1+HgsbEltdzUudzarsMtbV37moK2Le0damnrUHNb6vFgc5taguWW9g61Bo/NaduGe7qlmVRgppjZkeWC1HKswFRgpoJge/q+bu2Cfd2eU5B6Xl/7Oo9ZYKk6TKaCgtRj8L+u53YuK2iXquHIsqW166wvtWxdx+46TkFqn7q1C84frBx17uBuEOntrOf508/dVcvR508/TueGrrbp+7v2Wdey1P1c6fvTn6u05/R2bEs7uWV57PT3v9uxu613LqlHXZmPnf7PYrdjZzzXEI7d8z3ocezO15bNsdXt8+n72Ok1dD0/wzmOvLIj9QKZEMIwJhTGCjQumdC45PCcz93V1uHdglpbh6u93dXWkVpua3e1d/Sy3p56fvp6atnVntY+fb3DU8O7HR4su6ujw9XuLg/W23trF+xzV9Am877O5bZ2V7t3HGnXcaRd6vVLrtQ+d5d3bktb7gjqko4sH3mOpAzP70g1kmd4jno5J5BvugVGHR38Uvu6NzoqPOro8Jh+TGU6R4Zt3dePrB3dNvN504/Tbd8AgmrP/4A5uqajz91b/X29R50b0tu//9xpevdpkxUVQhgQAjNTPGaKxwpUWhR1NWObd4W17sHNXd2WO3qGxX6eo862wTk617s9ytOWj4TDI2167u9x7B7rmY595HhZHLuzzh7nkh/Z1t+xO8Nuej3d3oO083ff3/uxj3xW/R9baXX3d2z1eE96vkfpx04/f2/HVtr6ked0f5+lo+tJ36f015LhnL0dR0ft617nUe171OoZzttbjUee1/2fxUzHzvQ6MtV69Hkz1NXbObKstc9jd9XYfV/UP+oihAEY1dJ7AGKyvhsDwDDid/0AAAARIIQBAABEgBAGAAAQAUIYAABABAhhAAAAESCEAQAARIAQBgAAEAFCGAAAQAQIYQAAABEghAEAAESAEAYAABABQhgAAEAECGEAAAARMHePuoYBMbOdkjaHfJpaSbtCPgcGjs8lP/G55B8+k/zE55J/huMzmebudZl2jLgQNhzMbLm7z4+6DnTH55Kf+FzyD59JfuJzyT9RfyYMRwIAAESAEAYAABABQlhmd0VdADLic8lPfC75h88kP/G55J9IPxPmhAEAAESAnjAAAIAIEMJ6MLOLzWydma03s8VR1zNWmNkUM1tmZqvNbJWZ/UOwvdrMHjOzV4PHqmC7mdmS4HN6ycxOj/YVjG5mFjOz583sl8H6DDN7Nnj/f2RmiWB7UbC+Ptg/PdLCRykzG2dmD5nZWjNbY2bn8l2Jnpl9Mvj310ozu9/MivmuDD8zu9vMdpjZyrRtA/5+mNl1QftXzey6MGolhKUxs5ikOyVdImmOpKvNbE60VY0ZbZI+7e5zJJ0j6WPBe79Y0u/cfbak3wXrUuozmh38XS/pW8Nf8pjyD5LWpK1/SdJX3f04SXslfSjY/iFJe4PtXw3aIfe+LunX7n6CpFOV+mz4rkTIzCZJuknSfHc/SVJM0iLxXYnC9yRd3GPbgL4fZlYt6fOSzpZ0lqTPdwa3XCKEdXeWpPXuvtHdWyQ9IOnyiGsaE9z9TXf/U7DcoNT/qUxS6v2/N2h2r6QrguXLJX3fU56RNM7MJg5v1WODmU2WdKmk7wbrJultkh4KmvT8XDo/r4ckvT1ojxwxs0pJfy7pPyXJ3VvcfZ/4ruSDQkklZlYoKSnpTfFdGXbu/qSkPT02D/T78U5Jj7n7HnffK+kxHR3showQ1t0kSVvS1uuDbRhGQbf8aZKelTTe3d8Mdm2TND5Y5rMaPl+T9E+SOoL1Gkn73L0tWE9/77s+l2D//qA9cmeGpJ2S7gmGiL9rZqXiuxIpd98q6Q5JrysVvvZLWiG+K/lioN+PYfneEMKQV8ysTNJPJH3C3Q+k7/PUT3n5Oe8wMrN3Sdrh7iuirgVdCiWdLulb7n6apEM6MrQiie9KFIKhqsuVCsnHSipVCD0nGLp8+n4QwrrbKmlK2vrkYBuGgZnFlQpg/+XuPw02b+8cOgkedwTb+ayGxwJJl5nZJqWG59+m1HykccGQi9T9ve/6XIL9lZJ2D2fBY0C9pHp3fzZYf0ipUMZ3JVrvkPSau+9091ZJP1Xq+8N3JT8M9PsxLN8bQlh3z0maHfyaJaHUpMqHI65pTAjmQvynpDXu/pW0XQ9L6vxVynWS/jtt+/uDX7acI2l/WlczcsTdP+vuk919ulLfh9+7+zWSlkl6T9Cs5+fS+Xm9J2ifF//FOVq4+zZJW8zs+GDT2yWtFt+VqL0u6RwzSwb/Puv8XPiu5IeBfj8elXSRmVUFvZwXBdtyiou19mBmC5WaAxOTdLe73x5tRWODmZ0n6Q+SXtaRuUf/rNS8sAclTZW0WdJV7r4n+JfcfyjV3d8o6YPuvnzYCx9DzOwCSf/o7u8ys5lK9YxVS3pe0rXu3mxmxZLuU2pO3x5Ji9x9Y0Qlj1pmNk+pH0okJG2U9EGl/qOa70qEzOxWSe9V6tfez0v6sFLziPiuDCMzu1/SBZJqJW1X6leOP9cAvx9m9rdK/f+QJN3u7vfkvFZCGAAAwPBjOBIAACAChDAAAIAIEMIAAAAiQAgDAACIACEMAAAgAoQwACOembWb2Qtpf4v7f1bWx55uZitzdTwA6FTYfxMAyHuH3X1e1EUAwEDQEwZg1DKzTWb2ZTN72cz+n5kdF2yfbma/N7OXzOx3ZjY12D7ezH5mZi8Gf38WHCpmZt8xs1Vm9hszKwna32Rmq4PjPBDRywQwQhHCAIwGJT2GI9+btm+/u5+s1FWxvxZs+4ake939FEn/JWlJsH2JpCfc/VSl7se4Ktg+W9Kd7j5X0j5JVwbbF0s6LTjODeG8NACjFVfMBzDimdlBdy/LsH2TpLe5+8bgBvHb3L3GzHZJmujurcH2N9291sx2Sprs7s1px5gu6TF3nx2sf0ZS3N3/l5n9WtJBpW6J8nN3PxjySwUwitATBmC0816WB6I5bbldR+bTXirpTqV6zZ4zM+bZAsgaIQzAaPfetMeng+WnJC0Klq9R6ubxkvQ7SR+VJDOLmVllbwc1swJJU9x9maTPSKqUdFRvHAD0hv9qAzAalJjZC2nrv3b3zstUVJnZS0r1Zl0dbPu4pHvM7GZJOyV9MNj+D5LuMrMPKdXj9VFJb/ZyzpikHwRBzSQtcfd9OXo9AMYA5oQBGLWCOWHz3X1X1LUAQE8MRwIAAESAnjAAAIAI0BMGAAAQAUIYAABABAhhAAAAESCEAQAARIAQBgAAEAFCGAAAQAT+P5sjkYndueNmAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: Plot the cost function vs. number of iterations in the training set.\n",
        "\n",
        "def plot_cost_function(train_loss,   title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_loss, label='train loss')\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_cost_function(train_loss_cie,  'Science')\n",
        "plot_cost_function(train_loss_mat,  'Math')\n",
        "plot_cost_function(train_loss_lp,  'Portuguese')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfR862UoK9j6"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (449369750.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [46]\u001b[0;36m\u001b[0m\n\u001b[0;31m    *texto em itálico*\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "*texto em itálico*\n",
        "> What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xij-E5UUseS"
      },
      "source": [
        "5. (0.25 point) Pick **your best model**, based on your validation set, and predict the target values for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arthur/.local/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- Tipo_PROVA_A\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "X has 83 features, but SGDRegressor is expecting 84 features as input.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(model_cie_sgd\u001b[39m.\u001b[39;49mscore(X_test_cie, y_test_cie))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y161sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(model_mat_sgd\u001b[39m.\u001b[39mscore(X_test_mat, y_test_mat))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y161sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(model_lp_sgd\u001b[39m.\u001b[39mscore(X_test_lp, y_test_lp))\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:705\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \n\u001b[1;32m    665\u001b[0m \u001b[39mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 705\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    706\u001b[0m \u001b[39mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1581\u001b[0m, in \u001b[0;36mBaseSGDRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1569\u001b[0m     \u001b[39m\"\"\"Predict using the linear model.\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m \n\u001b[1;32m   1571\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[39m       Predicted target values per element in X.\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:1563\u001b[0m, in \u001b[0;36mBaseSGDRegressor._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[39m\"\"\"Predict using the linear model\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \n\u001b[1;32m   1552\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[39m   Predicted target values per element in X.\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1563\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1565\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m   1566\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 83 features, but SGDRegressor is expecting 84 features as input."
          ]
        }
      ],
      "source": [
        "print(model_cie_sgd.score(X_test_cie, y_test_cie))\n",
        "print(model_mat_sgd.score(X_test_mat, y_test_mat))\n",
        "print(model_lp_sgd.score(X_test_lp, y_test_lp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_PobUahUseS"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Remove the columns used as target in the linear regression\"\"\"\n",
        "def tranform_into_log_reg(df):\n",
        "    df = df.drop(columns=['porc_ACERT_lp',\n",
        "       'porc_ACERT_MAT', 'porc_ACERT_CIE'], axis=1)\n",
        "    return df\n",
        "df = tranform_into_log_reg(df)\n",
        "df_teste = tranform_into_log_reg(df_teste)\n",
        "type(df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['CD_ALUNO', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10',\n",
              "       'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20',\n",
              "       'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30',\n",
              "       'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40',\n",
              "       'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50',\n",
              "       'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60',\n",
              "       'Q61', 'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C',\n",
              "       'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_log = df\n",
        "df_log_teste = df_teste\n",
        "type(df_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
              "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
              "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31',\n",
              "       'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41',\n",
              "       'Q42', 'Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49', 'Q50', 'Q51',\n",
              "       'Q52', 'Q53', 'Q54', 'Q55', 'Q56', 'Q57', 'Q58', 'Q59', 'Q60', 'Q61',\n",
              "       'Q62', 'SERIE_ANO', 'TP_SEXO', 'Tem_Nec', 'nivel_profic_lp',\n",
              "       'nivel_profic_mat', 'nivel_profic_cie', 'Q63_A', 'Q63_B', 'Q63_C',\n",
              "       'Q63_D', 'RegiaoMetropolitana_Interior',\n",
              "       'RegiaoMetropolitana_Região Metropolitana da Baixada Santista',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Campinas',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Ribeirão Preto',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de Sorocaba',\n",
              "       'RegiaoMetropolitana_Região Metropolitana de São Paulo',\n",
              "       'RegiaoMetropolitana_Região Metropolitana do Vale do Paraíba e Litoral Norte',\n",
              "       'idade', 'PERIODO_MANHÃ', 'PERIODO_NOITE', 'PERIODO_TARDE',\n",
              "       'Tipo_PROVA_A', 'Tipo_PROVA_C'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_log.drop(columns=['CD_ALUNO'], axis=1, inplace=True)\n",
        "df_log_teste.drop(columns=['CD_ALUNO'], axis=1, inplace=True)\n",
        "df_log.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(df, target, validation_size):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    return train_test_split(X, y, test_size=validation_size, random_state=42)\n",
        "X_train_cie, X_val_cie, y_train_cie, y_val_cie = split_data(df_log, 'nivel_profic_cie', 0.2)\n",
        "X_train_mat, X_val_mat, y_train_mat, y_val_mat = split_data(df_log, 'nivel_profic_mat', 0.2)\n",
        "X_train_lp, X_val_lp, y_train_lp, y_val_lp = split_data(df_log, 'nivel_profic_lp', 0.2)\n",
        "X_teste_cie = df_log_teste.drop(columns=[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df)\n",
        "    return scaler.transform(df)\n",
        "X_train_cie = normalize_data(X_train_cie)\n",
        "X_val_cie = normalize_data(X_val_cie)\n",
        "X_train_mat = normalize_data(X_train_mat)\n",
        "X_val_mat = normalize_data(X_val_mat)\n",
        "X_train_lp = normalize_data(X_train_lp)\n",
        "X_val_lp = normalize_data(X_val_lp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCJuwjrAUseS"
      },
      "source": [
        "Now, this part of the assignment aims to predict students' proeficiency level on Portuguese, Mathematics, and Natural Sciences (target values: `nivel_profic_lp`, `nivel_profic_mat` and `nivel_profic_cie`) based on their socioeconomic data. Then, you have to **drop the columns `porc_ACERT_lp`,  `porc_ACERT_MAT`** and  **`porc_ACERT_CIE`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joYtn8avUseS"
      },
      "source": [
        "### Activities\n",
        "\n",
        "1. (2.75 points) Perform Multinomial Logistic Regression (_i.e._, softmax regression). It is a generalization of Logistic Regression to the case where we want to handle multiple classes. Try different combinations of features, dropping the ones less correlated to the target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-36Dt2V_UseT"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 80\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m, model_cie\u001b[39m.\u001b[39mscore(X_val_cie, y_val_cie))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMath\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model_mat \u001b[39m=\u001b[39m multinomial_logistic_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m, model_mat\u001b[39m.\u001b[39mscore(X_val_mat, y_val_mat))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPortuguese\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32m/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb Cell 80\u001b[0m in \u001b[0;36mmultinomial_logistic_regression\u001b[0;34m(X_train, y_train, X_val, y_val, num_epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultinomial_logistic_regression\u001b[39m(X_train, y_train, X_val, y_val, num_epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model \u001b[39m=\u001b[39m LogisticRegression(multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultinomial\u001b[39m\u001b[39m'\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m, max_iter\u001b[39m=\u001b[39m num_epochs, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/Documents/unicamp/mc886/Copy_of_2022s2_mc886mo444_assignment_02.ipynb#Y142sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[1;32m   1593\u001b[0m )(\n\u001b[1;32m   1594\u001b[0m     path_func(\n\u001b[1;32m   1595\u001b[0m         X,\n\u001b[1;32m   1596\u001b[0m         y,\n\u001b[1;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1615\u001b[0m )\n\u001b[1;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
            "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: Multinomial Logistic Regression. You can use scikit-learn libraries.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def multinomial_logistic_regression(X_train, y_train, X_val, y_val, num_epochs = 1000):\n",
        "    model = LogisticRegression(multi_class='multinomial', solver='sag', max_iter= num_epochs, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "print(\"Science\")\n",
        "model_cie = multinomial_logistic_regression(X_train_cie, y_train_cie, X_val_cie, y_val_cie)\n",
        "print(\"Accuracy: \", model_cie.score(X_val_cie, y_val_cie))\n",
        "print(\"Math\")\n",
        "model_mat = multinomial_logistic_regression(X_train_mat, y_train_mat, X_val_mat, y_val_mat)\n",
        "print(\"Accuracy: \", model_mat.score(X_val_mat, y_val_mat))\n",
        "print(\"Portuguese\")\n",
        "model_lp = multinomial_logistic_regression(X_train_lp, y_train_lp, X_val_lp, y_val_lp)\n",
        "print(\"Accuracy: \", model_lp.score(X_val_lp, y_val_lp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQj3oImUUseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb1KNEqLUseT"
      },
      "source": [
        "2. (0.5 point) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DisplayLossCurve(object):\n",
        "  def __init__(self, print_loss=False):\n",
        "    self.print_loss = print_loss\n",
        "\n",
        "  \"\"\"Make sure the model verbose is set to 1\"\"\"\n",
        "  def __enter__(self):\n",
        "    self.old_stdout = sys.stdout\n",
        "    sys.stdout = self.mystdout = io.StringIO()\n",
        "  \n",
        "  def __exit__(self, *args, **kwargs):\n",
        "    sys.stdout = self.old_stdout\n",
        "    loss_history = self.mystdout.getvalue()\n",
        "    loss_list = []\n",
        "    for line in loss_history.split('\\n'):\n",
        "      if(len(line.split(\"loss: \")) == 1):\n",
        "        continue\n",
        "      loss_list.append(float(line.split(\"loss: \")[-1]))\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(len(loss_list)), loss_list)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    if self.print_loss:\n",
        "      print(\"=============== Loss Array ===============\")\n",
        "      print(np.array(loss_list))\n",
        "      \n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.6s finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0, 'convergence after 66 epochs took 10 seconds\\n']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Function to capture the output of a cell in a notebook\"\"\"\n",
        "def capture_output(cell):\n",
        "    lista = []\n",
        "    stdout = sys.stdout\n",
        "    sys.stdout = io.StringIO()\n",
        "    cell()\n",
        "    sys.stdout.seek(0)\n",
        "    lista.append(sys.stdout.seek(0))\n",
        "    output = sys.stdout.read()\n",
        "    lista.append(output)\n",
        "    sys.stdout = stdout\n",
        "    return lista\n",
        "model = LogisticRegression(multi_class='multinomial', solver='sag', max_iter= 100, verbose=1)\n",
        "capture_output(lambda: model.fit(X_train_cie, y_train_cie))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial', solver='sag', verbose=1)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression(multi_class='multinomial', solver='sag', max_iter= 100, verbose=1)\n",
        "model.fit(X_train_cie, y_train_cie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('output.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IM4mx23UseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqlv9-6OUseT"
      },
      "source": [
        "3. (0.75 point) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jdyJuS0UseT"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot the confusion matrix. You can use scikit-learn, seaborn, matplotlib libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAmCj0cpUseT"
      },
      "source": [
        "> What are the conclusions? (1-2 paragraphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdSGS4brHnAi"
      },
      "source": [
        "## Deadline\n",
        "\n",
        "Monday, September 19, 11:59 pm. \n",
        "\n",
        "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
        "- September 20, 11:59 pm : grade * 0.75\n",
        "- September 21, 11:59 pm : grade * 0.5\n",
        "- September 22, 11:59 pm : grade * 0.25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joN9pvZJIfW5"
      },
      "source": [
        "## Submission\n",
        "\n",
        "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
        "\n",
        "**This activity is NOT individual, it must be done in pairs (two-person group).**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
